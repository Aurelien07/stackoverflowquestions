{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aurelien07/stackoverflowquestions/blob/main/Projet_5_topic_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "large-transcript",
      "metadata": {
        "id": "large-transcript"
      },
      "source": [
        "#  Stack Overflow part : 2/3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddb367dc",
      "metadata": {
        "id": "ddb367dc"
      },
      "source": [
        "Utilisation de la librairie Nb Extend pour mettre le code au format PEP 8."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour les installations de certaines librairies via pip ou upgrade \n",
        "!pip install gensim==4.2.0 # -> pour relancer le modéle \n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "co8dmEI0I0IZ"
      },
      "id": "co8dmEI0I0IZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "experienced-budapest",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:26:25.054815Z",
          "start_time": "2022-10-17T14:26:20.420771Z"
        },
        "id": "experienced-budapest"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import IPython.display\n",
        "import re\n",
        "\n",
        "# Permettra de créer des accés avec google drive\n",
        "import os \n",
        "\n",
        "# from contractions import CONTRACTION_MAP  # pour les verbes contractées\n",
        "# source : https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72\n",
        "\n",
        "# Pour la visualisation graphique :\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import LineCollection\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "# pour le modelling des mots :\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import lxml\n",
        "import html5lib\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Pour l'optimisation des algos :\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Pour le BOW :\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Pour le tf-idf :\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Pour la PCA : \n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import StandardScaler # classe pour standardisation\n",
        "from sklearn import preprocessing\n",
        "from sklearn import decomposition\n",
        "\n",
        "# Pour la LDA : \n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Pour la NMF :\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# pour les algorithmes supervisés :\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# pour les algorithmes supervisés pré-entrainés :\n",
        "import tensorflow_hub as tf_hub\n",
        "\n",
        "# Pour word2vec :\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import metrics as kmetrics\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "import gensim\n",
        "from gensim.models import Word2Vec,word2vec\n",
        "\n",
        "# Bert\n",
        "import os\n",
        "import transformers\n",
        "from transformers import *\n",
        "\n",
        "# Pour la visualisation des tokens :\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from yellowbrick.text import FreqDistVisualizer\n",
        "\n",
        "# Pour les scores :\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, jaccard_score, hamming_loss\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Pour supprimer les warnings :\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ce128f2",
      "metadata": {
        "id": "3ce128f2"
      },
      "source": [
        "## Fonction importante pour le modelling :"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Permet de visualiser les NaN du DF de façon globale : \n",
        "\n",
        "def pct_vals_miss(data:pd.DataFrame):\n",
        "    \n",
        "    \"\"\"\n",
        "    Permet d'avoir un % de cellules manquantes.\n",
        "\n",
        "    Parameters :\n",
        "    ----------\n",
        "    \n",
        "    data: :class:`Dataframe`\n",
        "    DataFrame avec le pourcentage de données manquantes sur l'intégralité du df.\n",
        "\n",
        "    \"\"\"\n",
        "    # avec un print possibilité d'avoir une visu par colonne\n",
        "    somme = 0\n",
        "    for i in list(data.columns):\n",
        "        somme += data[i].isna().sum()\n",
        "    return round((somme / (data.shape[0]*data.shape[1]))*100,2)"
      ],
      "metadata": {
        "id": "P_ThM53WWa9G"
      },
      "id": "P_ThM53WWa9G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame de visualisation des manquants :\n",
        "\n",
        "def miss_value (data:pd.DataFrame) :\n",
        "    \n",
        "    \"\"\"\n",
        "    Permet d'avoir un % de cellules manquantes.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    \n",
        "    data: :class:`Dataframe`\n",
        "    DataFrame avec les pourcentages de données manquantes par colonnes.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    print('-'*100)\n",
        "    print(\" \"*41,'\\033[1m'+ \"Données manquantes :\"+'\\033[0m') # Describe\n",
        "    print('-'*100)\n",
        "\n",
        "    dico = {} # on crée un dictionnaire de données\n",
        "    for col in data.columns:\n",
        "        dico[col] = []\n",
        "        dico[col].append(round((data[col].notnull().sum()/data.shape[0])*100,2))\n",
        "        dico[col].append(data[col].isnull().sum())\n",
        "        \n",
        "    df = pd.DataFrame.from_dict(data=dico, orient=\"index\", columns = [\"Pourcentages\", \"Données manquantes\"]).sort_values(by=\"Données manquantes\", ascending=True)\n",
        "    display(df)\n",
        "    \n",
        "    print('-'*100)\n",
        "    print(\" \"*25,'\\033[1m'+f\"Le pourcentage de données manquantes est de\",pct_vals_miss(data),\"%\"+'\\033[0m')\n",
        "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html => En cas de modif"
      ],
      "metadata": {
        "id": "AbTh4DsJWbn4"
      },
      "id": "AbTh4DsJWbn4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f62cd1e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:26:20.407691Z",
          "start_time": "2022-10-17T14:26:20.403246Z"
        },
        "id": "9f62cd1e"
      },
      "outputs": [],
      "source": [
        "# potentiellement à optimisé pour une meilleure visibilité :\n",
        "def visu_yellow(data):\n",
        "\n",
        "    # Load the text data\n",
        "\n",
        "    vectorizer = CountVectorizer()\n",
        "    docs = vectorizer.fit_transform(data)\n",
        "    features = vectorizer.get_feature_names_out()\n",
        "    # plt.figure(figsize=(18,12)) # Erreur => utilisation de size\n",
        "    visualizer = FreqDistVisualizer(\n",
        "        features=features, orient='v', size=(1080, 720))\n",
        "    visualizer.fit(docs)\n",
        "    visualizer.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multiscore(y_test, y_pred):\n",
        "\n",
        "    print(\"-\"*53)\n",
        "    print('')\n",
        "    print(\">\"*15, \"Accuracy :\",\n",
        "          '\\033[1m' + str(round(metrics.accuracy_score(y_test, y_pred), 2)) + '\\033[0m', \"<\"*20), \n",
        "    print('')\n",
        "    print(\"-\"*53)\n",
        "    print('')\n",
        "    print(\">\"*15, \"Hamming loss :\",\n",
        "          '\\033[1m' + str(round(metrics.hamming_loss(y_test, y_pred), 2)) + '\\033[0m', \"<\"*17), # Pour les données qui ont été mal prédit\n",
        "    print('')\n",
        "    print(\"-\"*53)\n",
        "    print('')\n",
        "    print(\">\"*15, \"Jaccard_score :\", '\\033[1m' + str(round(metrics.jaccard_score(y_test, y_pred, average=\"weighted\"), 2))\n",
        "          + '\\033[0m', \"<\"*16),\n",
        "    print('')\n",
        "    print(\"-\"*53)\n",
        "    print('')\n",
        "    print(\">\"*15, \"f1_macro_score :\", '\\033[1m' + str(round(metrics.f1_score(y_test, y_pred, average='macro'), 2))\n",
        "          + '\\033[0m', \"<\"*16),\n",
        "    print('')\n",
        "    print(\"-\"*53)\n",
        "    print('')\n",
        "    print(\">\"*15, \"f1_micro_score :\", '\\033[1m' + str(round(metrics.f1_score(y_test, y_pred, average='micro'), 2))\n",
        "          + '\\033[0m', \"<\"*16),\n",
        "    print('')\n",
        "    print(\"-\"*53)\n",
        "    print('')\n",
        "    print(\">\"*15, \"Recall_micro_score :\", '\\033[1m' + str(round(metrics.f1_score(y_test, y_pred, average='micro'), 2)) # Pour controler les True positives\n",
        "          + '\\033[0m', \"<\"*16),\n",
        "    print('')\n",
        "    print(\"-\"*53)\n",
        "    print('')\n",
        "    print(\">\"*15, \"Recall_macro_score :\", '\\033[1m' + str(round(metrics.f1_score(y_test, y_pred, average='macro'), 2)) # Pour controler les True positives\n",
        "          + '\\033[0m', \"<\"*16),\n",
        "    print('')\n",
        "    print(\"-\"*53)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "eh6Jx5DUWQn9"
      },
      "id": "eh6Jx5DUWQn9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dico_metric (dico, col) :\n",
        "\n",
        "  \"\"\"\n",
        "  source : https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "  Permet de créer un dictionnaire avec les scores des differents algorithmes.\n",
        "  \"\"\"\n",
        "  dico[col]  = {'Accuracy': round(metrics.accuracy_score(y_test, y_pred), 2) ,\n",
        "                'Hamming loss' : round(metrics.hamming_loss(y_test, y_pred), 2),\n",
        "                'Jaccard_score_macro' : round(metrics.jaccard_score(y_test, y_pred, average=\"macro\"), 2),\n",
        "                'Jaccard_score_micro' : round(metrics.jaccard_score(y_test, y_pred, average=\"micro\"), 2),\n",
        "                'f1_macro_score' : round(metrics.f1_score(y_test, y_pred, average='macro'), 2),\n",
        "                'f1_micro_score' : round(metrics.f1_score(y_test, y_pred, average='micro'), 2),\n",
        "                'Recall_micro_score' : round(metrics.f1_score(y_test, y_pred, average='micro'), 2),\n",
        "                'Recall_macro_score' : round(metrics.f1_score(y_test, y_pred, average='macro'), 2),\n",
        "                'precision_score' : round(metrics.precision_score(y_test, y_pred, average='macro'), 2),\n",
        "               # 'roc_AUC__macro_score' :  \tround(metrics.roc_auc_score(y_test, y_pred, average='macro'), 2),\n",
        "               # 'roc_AUC__micro_score' :  \tround(metrics.roc_auc_score(y_test, y_pred, average='micro'), 2)\n",
        "                }\n",
        "  return dico"
      ],
      "metadata": {
        "id": "9yaoP3GkCfNl"
      },
      "id": "9yaoP3GkCfNl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "multiple-termination",
      "metadata": {
        "id": "multiple-termination"
      },
      "source": [
        "## Importation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invisible-preparation",
      "metadata": {
        "id": "invisible-preparation"
      },
      "source": [
        "Pour les besoins du notebook nous ne conservons que les titres, corps du texte et tags des document importés. \n",
        "\n",
        "Nous créons également un chemin pour utiliser nos fichiers dans le drive."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DfTO8_Z6hGoW"
      },
      "id": "DfTO8_Z6hGoW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/My Drive/Colab Notebooks/Projet_5/\""
      ],
      "metadata": {
        "id": "S4WTqQxKkw1b"
      },
      "id": "S4WTqQxKkw1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d5afff5c",
      "metadata": {
        "id": "d5afff5c"
      },
      "source": [
        "### Pré-visualisation avant traitement :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb0ab10",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:26:25.897527Z",
          "start_time": "2022-10-17T14:26:25.055831Z"
        },
        "id": "dbb0ab10"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Projet_5/P5_exploration.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "continuing-affiliate",
      "metadata": {
        "id": "continuing-affiliate"
      },
      "source": [
        "## Pré-traitement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6689dabc",
      "metadata": {
        "id": "6689dabc"
      },
      "source": [
        "Pour chacune de nos opérations, nous allons utiliser la fonction %%time pour nous permettre de connaître le temps entre chaque opération.\n",
        "\n",
        "En considérant le temps entre chaque opération, si l'opération est trop longue, il conviendra de faire un pickle pour le garder en mémoire."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d1a251b",
      "metadata": {
        "id": "7d1a251b"
      },
      "source": [
        "### Suppression des balises Tags :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efbc05d1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:26:26.067813Z",
          "start_time": "2022-10-17T14:26:25.898325Z"
        },
        "id": "efbc05d1"
      },
      "outputs": [],
      "source": [
        "# Preprocess les tags\n",
        "data[\"Tags\"] = data[\"Tags\"].str.lower() \n",
        "data[\"Tags\"] = data[\"Tags\"].replace({\"><\" : \" \"}, regex=True)\n",
        "data[\"Tags\"] = data[\"Tags\"].replace({\"<\" : \"\"}, regex=True)\n",
        "data[\"Tags\"] = data[\"Tags\"].replace({\">\" : \"\"}, regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cultural-supplier",
      "metadata": {
        "id": "cultural-supplier"
      },
      "source": [
        "### Création de la colonne corpus :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "applicable-mayor",
      "metadata": {
        "id": "applicable-mayor"
      },
      "source": [
        "Nous commençons par créer une nouvelle variable associant le titre (Title) et le corps du texte (Body)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d93cef24",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:26:26.177598Z",
          "start_time": "2022-10-17T14:26:26.069070Z"
        },
        "id": "d93cef24"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "data['Corpus'] = data['Title'] + ' ' + data['Body']\n",
        "# Certains algorithmes auront besoin d'une liste\n",
        "corpus = data['Corpus'].to_list()\n",
        "# Certains algorithmes auront besoin d'une liste\n",
        "tags = data['Tags'].to_list()\n",
        "display(data.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6319eefd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:26:26.186199Z",
          "start_time": "2022-10-17T14:26:26.180252Z"
        },
        "id": "6319eefd"
      },
      "outputs": [],
      "source": [
        "print(\"Visualisation pré-nettoyage du Corpus :\")\n",
        "print('')\n",
        "display(data.Corpus[0])\n",
        "print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "accessory-rebound",
      "metadata": {
        "id": "accessory-rebound"
      },
      "source": [
        "### Nettoyage HTML via beautiful soup :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "utility-consistency",
      "metadata": {
        "id": "utility-consistency"
      },
      "source": [
        "Nous allons maintenant nettoyer les données en rapport avec les balises HTML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wired-depth",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:10.109511Z",
          "start_time": "2022-10-17T14:26:26.190076Z"
        },
        "id": "wired-depth"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "def clean_html(text_html):\n",
        "    soup = BeautifulSoup(text_html, \"html5lib\")\n",
        "    for element in soup.find_all(\"code\"):\n",
        "        # print(element)\n",
        "        element.decompose()\n",
        "    return soup.get_text().replace(\"\\n\", \" \")\n",
        "\n",
        "\n",
        "corpus_del_bal = [clean_html(text) for text in corpus]\n",
        "data['Corpus'] = data['Corpus'].apply(lambda x : clean_html(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62399946",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:10.113367Z",
          "start_time": "2022-10-17T14:28:10.110492Z"
        },
        "id": "62399946"
      },
      "outputs": [],
      "source": [
        "print(\"Visualisation du nettoyage Beautiful Soup :\")\n",
        "print('')\n",
        "display(corpus_del_bal[0])\n",
        "print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76f49de8",
      "metadata": {
        "id": "76f49de8"
      },
      "source": [
        "#### Visualisation Yellowbricks en token :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aac82a4f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:12.201047Z",
          "start_time": "2022-10-17T14:28:10.114256Z"
        },
        "id": "aac82a4f"
      },
      "outputs": [],
      "source": [
        "visu_yellow(corpus_del_bal)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dae84ba",
      "metadata": {
        "id": "7dae84ba"
      },
      "source": [
        "On voit qu'il y a toujours des mots redondants qui ne servent à rien à l'analyse."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "direct-savannah",
      "metadata": {
        "id": "direct-savannah"
      },
      "source": [
        "### Nettoyage du texte (Suppression des fins de lignes et des chiffres) :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af5c65d2",
      "metadata": {
        "id": "af5c65d2"
      },
      "source": [
        "ici, nous supprimons les fins de lignes et les chiffres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "compliant-wayne",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:19.379500Z",
          "start_time": "2022-10-17T14:28:12.202202Z"
        },
        "id": "compliant-wayne"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "def text_cleaning(text):\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)  # supprimer tout les chiffres\n",
        "    text = re.sub(r'\\n', '', text)  # retirer les fins de lignes\n",
        "    text = re.sub(r'\\s+', ' ', text)  # retirer les fins de lignes de corpus\n",
        "    # text = re.split(\",\" , \" \")\n",
        "    return text\n",
        "\n",
        "\n",
        "corpus_x = [text_cleaning(text) for text in corpus_del_bal]  # pour la liste\n",
        "tags_x = [text_cleaning(text).strip() for text in tags]  # pour la liste\n",
        "data['Corpus'] = data['Corpus'].apply(lambda x : text_cleaning(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "923bdfe7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:19.384671Z",
          "start_time": "2022-10-17T14:28:19.380615Z"
        },
        "id": "923bdfe7"
      },
      "outputs": [],
      "source": [
        "print('-'*45)\n",
        "print(\"Visualisation du nettoyage texte sur le corpus :\")\n",
        "print('-'*45)\n",
        "display(corpus_x[0])\n",
        "print(\"\")\n",
        "\n",
        "print('-'*45)\n",
        "print(\"Visualisation du nettoyage texte sur les tags :\")\n",
        "print('-'*45)\n",
        "display(tags_x[0])\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55950378",
      "metadata": {
        "id": "55950378"
      },
      "source": [
        "#### Visualisation Yellowbricks en token :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd55f6ad",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:21.344810Z",
          "start_time": "2022-10-17T14:28:19.385590Z"
        },
        "id": "cd55f6ad"
      },
      "outputs": [],
      "source": [
        "visu_yellow(corpus_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cad7f251",
      "metadata": {
        "id": "cad7f251"
      },
      "source": [
        "Le corpus pré-nettoyé reste actuellement inutilisable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0faf734",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:21.697603Z",
          "start_time": "2022-10-17T14:28:21.345892Z"
        },
        "id": "c0faf734"
      },
      "outputs": [],
      "source": [
        "visu_yellow(tags_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46886262",
      "metadata": {
        "id": "46886262"
      },
      "source": [
        "Ici, on peut voir que les Tags sont bien représentés."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8ac08eb",
      "metadata": {
        "id": "c8ac08eb"
      },
      "source": [
        "### Suppression des verbes contractées :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "522975f8",
      "metadata": {
        "id": "522975f8"
      },
      "source": [
        "Suppression des formes contractés des verbes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONTRACTION_MAP = {\n",
        "\"ain't\": \"is not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"I'd\": \"I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\n",
        "\"I'll've\": \"I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'd've\": \"i would have\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'll've\": \"i will have\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "metadata": {
        "id": "Wx9BemPHw1uz"
      },
      "id": "Wx9BemPHw1uz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "907d5ca3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:21.703032Z",
          "start_time": "2022-10-17T14:28:21.699270Z"
        },
        "id": "907d5ca3"
      },
      "outputs": [],
      "source": [
        "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
        "\n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
        "                                      flags=re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contraction_mapping.get(match)\\\n",
        "            if contraction_mapping.get(match)\\\n",
        "            else contraction_mapping.get(match.lower())\n",
        "        expanded_contraction = first_char+expanded_contraction[1:]\n",
        "        return expanded_contraction\n",
        "\n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8218fa54",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:49.337334Z",
          "start_time": "2022-10-17T14:28:21.704038Z"
        },
        "id": "8218fa54"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "corpus_x = [expand_contractions(text) for text in corpus_del_bal]\n",
        "tags_x = [expand_contractions(text).strip() for text in tags]\n",
        "# data['Corpus'] = data['Corpus'].apply(lambda x : expand_contractions(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed594f19",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:49.343515Z",
          "start_time": "2022-10-17T14:28:49.338306Z"
        },
        "id": "ed594f19"
      },
      "outputs": [],
      "source": [
        "print('-'*60)\n",
        "print(\"Visualisation de la suppression des verbes contractés sur le corpus :\")\n",
        "print('-'*60)\n",
        "display(corpus_x[0])\n",
        "print(\"\")\n",
        "\n",
        "print('-'*60)\n",
        "print(\"Visualisation de la suppression des verbes contractés sur les tags :\")\n",
        "print('-'*60)\n",
        "display(tags_x[0])\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da26b527",
      "metadata": {
        "id": "da26b527"
      },
      "source": [
        "#### Visualisation Yellowbricks en token :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "623b6c46",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:51.902636Z",
          "start_time": "2022-10-17T14:28:49.344413Z"
        },
        "id": "623b6c46"
      },
      "outputs": [],
      "source": [
        "visu_yellow(corpus_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04913499",
      "metadata": {
        "id": "04913499"
      },
      "source": [
        "Peu de difference ici, vu que les mots contractées ne doivent pas être dans le top 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe3524e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:52.254661Z",
          "start_time": "2022-10-17T14:28:51.903597Z"
        },
        "id": "3fe3524e"
      },
      "outputs": [],
      "source": [
        "visu_yellow(tags_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21c772d3",
      "metadata": {
        "id": "21c772d3"
      },
      "source": [
        "Idem les tags étant déjà des termes spécifiques, pas de raison de retrouver une difference entre les 2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "primary-naples",
      "metadata": {
        "id": "primary-naples"
      },
      "source": [
        "### Tokenization + suppression des stopwords :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dffb5d90",
      "metadata": {
        "id": "dffb5d90"
      },
      "source": [
        "La tokenisation consiste essentielleent à diviser une phrase, paragraphe ou un document de texte en unités plus petites, entant que mots ou termes individuels. On appelle ces mots des tokens d'ou tokenisation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cb9b1e4",
      "metadata": {
        "id": "7cb9b1e4"
      },
      "source": [
        "Un stopword est un mot qui est tellement commun qu'il est inutile de l'indexer ou de l'utiliser dans une recherche."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe286d84",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:52.657155Z",
          "start_time": "2022-10-17T14:28:52.255811Z"
        },
        "id": "fe286d84"
      },
      "outputs": [],
      "source": [
        "import string  # permet d'avoir accés à toute les ponctuations.\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "moral-closure",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:28:52.668218Z",
          "start_time": "2022-10-17T14:28:52.661250Z"
        },
        "scrolled": false,
        "id": "moral-closure"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    punctuation = set(string.punctuation)\n",
        "\n",
        "    try:\n",
        "        res = word_tokenize(text, language='english')\n",
        "    except TypeError:\n",
        "        return text\n",
        "\n",
        "    res = [token for token in res if token not in punctuation]\n",
        "    res = [token for token in res if token not in stop_words]\n",
        "   # res = [token for token in res if token not in letters]\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac59fa7b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:29:21.530462Z",
          "start_time": "2022-10-17T14:28:52.671222Z"
        },
        "id": "ac59fa7b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "corpus_token = [tokenize(text) for text in corpus_x]\n",
        "tag_token = [tokenize(text) for text in tags_x]\n",
        "# data['Corpus'] = data['Corpus'].apply(lambda x : tokenize(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c7733ee",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:29:21.536369Z",
          "start_time": "2022-10-17T14:29:21.531349Z"
        },
        "scrolled": false,
        "id": "3c7733ee"
      },
      "outputs": [],
      "source": [
        "print('-'*65)\n",
        "print(\"Visualisation de la suppression de la tokennisation sur le corpus :\")\n",
        "print('-'*65)\n",
        "display(corpus_token[0])\n",
        "print(\"\")\n",
        "\n",
        "print('-'*65)\n",
        "print(\"Visualisation de la suppression de la tokennisation sur les tags :\")\n",
        "print('-'*65)\n",
        "display(tag_token[0])\n",
        "print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "honey-basement",
      "metadata": {
        "id": "honey-basement"
      },
      "source": [
        "###  POS tagging :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "481c2b3d",
      "metadata": {
        "id": "481c2b3d"
      },
      "source": [
        "Parts of Speech (POS) Tagging. Parts of speech tagging simply refers to assigning parts of speech to individual words in a sentence, which means that, unlike phrase matching, which is performed at the sentence or multi-word level, parts of speech tagging is performed at the token level.\n",
        "\n",
        "source : https://stackabuse.com/python-for-nlp-parts-of-speech-tagging-and-named-entity-recognition/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b38fa55",
      "metadata": {
        "id": "4b38fa55"
      },
      "source": [
        "NN: noun, common, singular or mass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "oPZtaSsYyvCO"
      },
      "id": "oPZtaSsYyvCO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abstract-settlement",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:29:21.540052Z",
          "start_time": "2022-10-17T14:29:21.537264Z"
        },
        "scrolled": false,
        "id": "abstract-settlement"
      },
      "outputs": [],
      "source": [
        "def filtering_nouns(text):\n",
        "\n",
        "    res = nltk.pos_tag(text)\n",
        "\n",
        "    res = [token[0] for token in res if token[1] == 'NN']# Rajouter adverbe etc etc\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76b1ecbb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:40.538151Z",
          "start_time": "2022-10-17T14:29:21.541236Z"
        },
        "id": "76b1ecbb"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "nn_corpus = [filtering_nouns(tokens) for tokens in corpus_token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8d67dd1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:40.547258Z",
          "start_time": "2022-10-17T14:30:40.544187Z"
        },
        "id": "c8d67dd1"
      },
      "outputs": [],
      "source": [
        "print('-'*65)\n",
        "print(\"Visualisation du POS Tagging sur le corpus :\")\n",
        "print('-'*65)\n",
        "display(nn_corpus[0])\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "color-bargain",
      "metadata": {
        "id": "color-bargain"
      },
      "source": [
        "### Lemmatisation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d963dfcb",
      "metadata": {
        "id": "d963dfcb"
      },
      "source": [
        "La lemmatisation désigne un traitement lexical apporté à un texte en vue de son classement dans un index ou de son analyse. Ce traitement consiste à appliquer aux occurrences des lexèmes sujets à flexion un codage renvoyant à leur entrée lexicale commune, que l'on désigne sous le terme de lemme.\n",
        "\n",
        "source : Wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6c6f23a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:40.555697Z",
          "start_time": "2022-10-17T14:30:40.548242Z"
        },
        "id": "d6c6f23a"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "loved-improvement",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:40.559271Z",
          "start_time": "2022-10-17T14:30:40.556688Z"
        },
        "id": "loved-improvement"
      },
      "outputs": [],
      "source": [
        "def lemmatisation(text):\n",
        "\n",
        "    # Init the Wordnet Lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    res = [lemmatizer.lemmatize(word, wordnet.VERB) for word in text]\n",
        "    res = [lemmatizer.lemmatize(word, wordnet.ADJ) for word in res]\n",
        "    res = [lemmatizer.lemmatize(word, wordnet.NOUN) for word in res]\n",
        "    res = [lemmatizer.lemmatize(word, wordnet.ADV) for word in res]\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45177108",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.220466Z",
          "start_time": "2022-10-17T14:30:40.560121Z"
        },
        "id": "45177108"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "corpus_lem = [lemmatisation(tokens) for tokens in nn_corpus]\n",
        "tags_lem = [lemmatisation(tokens) for tokens in tag_token]\n",
        "# data['Corpus'] = data['Corpus'].apply(lambda x : lemmatisation(x))\n",
        "\n",
        "tags_liste = []\n",
        "for tokens in tags_lem:\n",
        "    tokens = [token for token in tokens if len(token) > 1]\n",
        "    tags_liste.append(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f191138",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.225679Z",
          "start_time": "2022-10-17T14:30:47.221379Z"
        },
        "id": "3f191138"
      },
      "outputs": [],
      "source": [
        "print('-'*65)\n",
        "print(\"Visualisation de la lemmatisation sur le corpus :\")\n",
        "print('-'*65)\n",
        "display(corpus_lem[0])\n",
        "print(\"\")\n",
        "\n",
        "print('-'*65)\n",
        "print(\"Visualisation de la lemmatisation sur les Tags\")\n",
        "print('-'*65)\n",
        "display(tags_lem[0])\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "governmental-paraguay",
      "metadata": {
        "id": "governmental-paraguay"
      },
      "source": [
        "# Features Engineering :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "reliable-butter",
      "metadata": {
        "id": "reliable-butter"
      },
      "source": [
        "## Création des colonnes de preprocessing et création d'un nouveau DF :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc403b29",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.249403Z",
          "start_time": "2022-10-17T14:30:47.226678Z"
        },
        "id": "fc403b29"
      },
      "outputs": [],
      "source": [
        "# remettre sous forme de phrase et non sous forme de liste\n",
        "corpus_df = [\" \".join(text) for text in corpus_lem]\n",
        "# On crée un dataframe\n",
        "corpus_df = pd.DataFrame(corpus_df, columns=['corpus_preprocessing'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ba45820",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.256972Z",
          "start_time": "2022-10-17T14:30:47.250396Z"
        },
        "id": "7ba45820"
      },
      "outputs": [],
      "source": [
        "corpus_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f24fa385",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.267214Z",
          "start_time": "2022-10-17T14:30:47.258024Z"
        },
        "id": "f24fa385"
      },
      "outputs": [],
      "source": [
        "tags_df = [\" \".join(tags) for tags in tags_liste]\n",
        "tags_df = pd.DataFrame(tags_df, columns=['tags_preprocessing'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3de439c8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.273964Z",
          "start_time": "2022-10-17T14:30:47.268416Z"
        },
        "id": "3de439c8"
      },
      "outputs": [],
      "source": [
        "tags_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05baf4b6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.278074Z",
          "start_time": "2022-10-17T14:30:47.274896Z"
        },
        "id": "05baf4b6"
      },
      "outputs": [],
      "source": [
        "df_final = pd.concat([corpus_df, tags_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8124ceb4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.345770Z",
          "start_time": "2022-10-17T14:30:47.278945Z"
        },
        "id": "8124ceb4"
      },
      "outputs": [],
      "source": [
        "df_final['corpus_preprocessing'] = df_final['corpus_preprocessing'].apply(\n",
        "    lambda x: x.split(' '))\n",
        "df_final['tags_preprocessing'] = df_final['tags_preprocessing'].apply(\n",
        "    lambda x: x.split(' '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d5507e1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.357981Z",
          "start_time": "2022-10-17T14:30:47.346880Z"
        },
        "id": "0d5507e1"
      },
      "outputs": [],
      "source": [
        "corpus_final = df_final['corpus_preprocessing'].to_list()\n",
        "tags_final = df_final['tags_preprocessing'].to_list()\n",
        "data_corpus_base = data['Corpus'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07a73bb9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.366179Z",
          "start_time": "2022-10-17T14:30:47.359928Z"
        },
        "id": "07a73bb9"
      },
      "outputs": [],
      "source": [
        "df_visualisation = pd.concat([data['Corpus'],\n",
        "                              data['Tags'],\n",
        "                              df_final['corpus_preprocessing'],\n",
        "                              df_final['tags_preprocessing']],\n",
        "                             axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1818708b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.374420Z",
          "start_time": "2022-10-17T14:30:47.367221Z"
        },
        "scrolled": false,
        "id": "1818708b"
      },
      "outputs": [],
      "source": [
        "display(df_visualisation.head())\n",
        "# Ici on voit bien qu'on a nos tags modifiés et non modifiés,.\n",
        "# on pourra supprimer les balises via regex par la suite pour les tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10faf293",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.378515Z",
          "start_time": "2022-10-17T14:30:47.376407Z"
        },
        "id": "10faf293"
      },
      "outputs": [],
      "source": [
        "# Faire un CSV to dataframe pour éviter de tout relancer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "659191c6",
      "metadata": {
        "id": "659191c6"
      },
      "source": [
        "Avant de calculer le bag of Word, le tf idf et le nmf, on va réduire le nombre de tags pour notre analyse."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "199a74ba",
      "metadata": {
        "id": "199a74ba"
      },
      "source": [
        "## Comptage des Tags :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fd60600",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.404899Z",
          "start_time": "2022-10-17T14:30:47.380345Z"
        },
        "id": "2fd60600"
      },
      "outputs": [],
      "source": [
        "df_visualisation[\"Tags_count\"] = df_visualisation[\"Tags\"].apply(lambda x : len(x.split()))\n",
        "df_visualisation.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b6c0cf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.504795Z",
          "start_time": "2022-10-17T14:30:47.405970Z"
        },
        "id": "62b6c0cf"
      },
      "outputs": [],
      "source": [
        "#define data\n",
        "plt.figure(figsize=(12,12))\n",
        "data = df_visualisation[\"Tags_count\"].value_counts()\n",
        "labels = ['1 tag', '2 tags', '3 tags', '4 tags', '5 tags']\n",
        "\n",
        "#define Seaborn color palette to use\n",
        "colors = sns.color_palette('bright')[0:5]\n",
        "\n",
        "#create pie chart\n",
        "plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%')\n",
        "plt.legend(labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f233190a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.509498Z",
          "start_time": "2022-10-17T14:30:47.505973Z"
        },
        "id": "f233190a"
      },
      "outputs": [],
      "source": [
        "print( \"Le nombre de Tags dans une question est au nombre de : \", '\\033[1m'+ str(round(df_visualisation[\"Tags_count\"].mean(),2)) + '\\033[0m')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca8fbc52",
      "metadata": {
        "id": "ca8fbc52"
      },
      "source": [
        "# Enregistrer le dataframe dans un CSV :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "920c43db",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.513054Z",
          "start_time": "2022-10-17T14:30:47.510625Z"
        },
        "id": "920c43db"
      },
      "outputs": [],
      "source": [
        "#df_visualisation.to_csv(\"/content/drive/My Drive/Colab Notebooks/Projet_5/P5_xxx.csv\", index=True) # Cela permettra d'éviter d'attendre de relancer le notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Projet_5/P5_algorithme.csv\")"
      ],
      "metadata": {
        "id": "rNik9SCMtBkn"
      },
      "id": "rNik9SCMtBkn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dd7cc95b",
      "metadata": {
        "id": "dd7cc95b"
      },
      "source": [
        "# Analyse non supervisée :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af246a1d",
      "metadata": {
        "id": "af246a1d"
      },
      "source": [
        "## BOW :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1d3ce0b",
      "metadata": {
        "id": "b1d3ce0b"
      },
      "source": [
        "### Pour les tags : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "228782a1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.621826Z",
          "start_time": "2022-10-17T14:30:47.528691Z"
        },
        "id": "228782a1"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(tokenizer = lambda x: x.split())\n",
        "tag_bow = vectorizer.fit_transform(df_visualisation['Tags'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12de9f44",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.625277Z",
          "start_time": "2022-10-17T14:30:47.622878Z"
        },
        "id": "12de9f44"
      },
      "outputs": [],
      "source": [
        "print(\"Nombres de questions :\", tag_bow.shape[0])\n",
        "print(\"Nombres de tags uniques :\", tag_bow.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "350cf7fd",
      "metadata": {
        "id": "350cf7fd"
      },
      "source": [
        "Visualisation des 10 premiers Tags :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb27650",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.632605Z",
          "start_time": "2022-10-17T14:30:47.626282Z"
        },
        "id": "fbb27650"
      },
      "outputs": [],
      "source": [
        "tags_name = vectorizer.get_feature_names_out()\n",
        "print(\"Visualisation des 10 premiers tags pour le BOW :\", tags_name[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a88a4845",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.638155Z",
          "start_time": "2022-10-17T14:30:47.633718Z"
        },
        "id": "a88a4845"
      },
      "outputs": [],
      "source": [
        "frequence = tag_bow.sum(axis=0).A1 # Equivalent to ravel\n",
        "tag_dict = dict(zip(tags, frequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e4e4dc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.643171Z",
          "start_time": "2022-10-17T14:30:47.639157Z"
        },
        "id": "d1e4e4dc"
      },
      "outputs": [],
      "source": [
        "liste = []\n",
        "for key, value in tag_dict.items():\n",
        "  liste.append([key, value]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e298c115",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.651493Z",
          "start_time": "2022-10-17T14:30:47.644088Z"
        },
        "id": "e298c115"
      },
      "outputs": [],
      "source": [
        "tag_counting = pd.DataFrame(liste, columns=['Tags', 'Counts'])\n",
        "tag_counting.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da1c443a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.659489Z",
          "start_time": "2022-10-17T14:30:47.652590Z"
        },
        "id": "da1c443a"
      },
      "outputs": [],
      "source": [
        "display(tag_counting.max())\n",
        "display(tag_counting.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3c368aa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.733264Z",
          "start_time": "2022-10-17T14:30:47.660286Z"
        },
        "id": "d3c368aa"
      },
      "outputs": [],
      "source": [
        "tag_counting_graph = tag_counting.sort_values(['Counts'], ascending=False)\n",
        "plt.plot(tag_counting_graph['Counts'].values)\n",
        "plt.grid(True)\n",
        "plt.title(\"Distribution des Tags :\")\n",
        "plt.xlabel(\"Nombre de Tags sur les plus fréquents\")\n",
        "plt.ylabel(\"Fréquence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec9017a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.809599Z",
          "start_time": "2022-10-17T14:30:47.734683Z"
        },
        "id": "9ec9017a"
      },
      "outputs": [],
      "source": [
        "plt.plot(tag_counting_graph['Counts'][0:100].values)\n",
        "plt.grid(True)\n",
        "plt.title(\"Distribution des top 100 Tags :\")\n",
        "plt.xlabel(\"Nombre de Tags sur les plus fréquents\")\n",
        "plt.ylabel(\"Fréquence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a2499c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.881454Z",
          "start_time": "2022-10-17T14:30:47.812032Z"
        },
        "id": "77a2499c"
      },
      "outputs": [],
      "source": [
        "plt.plot(tag_counting_graph['Counts'][0:10].values)\n",
        "plt.grid(True)\n",
        "plt.title(\"Distribution des top 10 Tags :\")\n",
        "plt.xlabel(\"Nombre de Tags sur les plus fréquents\")\n",
        "plt.ylabel(\"Fréquence\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d51aaa8c",
      "metadata": {
        "id": "d51aaa8c"
      },
      "source": [
        "On peut voir qu'à partir de 8 on commence à avoir une fréquence inférieur à 1000, on aurait donc tendance à garder 1000 en fréquence.\n",
        "\n",
        "Et 8 en tag number max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "931c70c9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.889563Z",
          "start_time": "2022-10-17T14:30:47.882871Z"
        },
        "id": "931c70c9"
      },
      "outputs": [],
      "source": [
        "print(\"{} tags qui sont utilisés plus de 10 fois\".format(tag_counting[tag_counting[\"Counts\"]>10].shape[0]))\n",
        "print(\"{} tags qui sont utilisés plus de 25 fois\".format(tag_counting[tag_counting[\"Counts\"]>25].shape[0]))\n",
        "print(\"{} tags qui sont utilisés plus de 50 fois\".format(tag_counting[tag_counting[\"Counts\"]>50].shape[0]))\n",
        "print(\"{} tags qui sont utilisés plus de 100 fois\".format(tag_counting[tag_counting[\"Counts\"]>100].shape[0]))\n",
        "print(\"{} tags qui sont utilisés plus de 200 fois\".format(tag_counting[tag_counting[\"Counts\"]>200].shape[0]))\n",
        "print(\"{} tags qui sont utilisés plus de 500 fois\".format(tag_counting[tag_counting[\"Counts\"]>500].shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "605e8618",
      "metadata": {
        "id": "605e8618"
      },
      "source": [
        "On peut voir confirmation que le top 206 tags sont utilisés plus de 50x, donc interessant à mettre en place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e9785f6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.894350Z",
          "start_time": "2022-10-17T14:30:47.890904Z"
        },
        "id": "5e9785f6"
      },
      "outputs": [],
      "source": [
        "\"\"\"df_visualisation['Corpus'] = df_visualisation['Corpus'].str.lower()\n",
        "df_visualisation['Corpus'] = df_visualisation['Corpus'].apply(lambda x : tokenize(x))\n",
        "df_visualisation['Corpus'] = df_visualisation['Corpus'].apply(lambda x : filtering_nouns(x))\n",
        "df_visualisation['Corpus'] = df_visualisation['Corpus'].apply(lambda x : lemmatisation(x))\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe57ee6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.919768Z",
          "start_time": "2022-10-17T14:30:47.896071Z"
        },
        "id": "3fe57ee6"
      },
      "outputs": [],
      "source": [
        "df_visualisation[\"Corpus\"] = df_visualisation[\"corpus_preprocessing\"].apply(lambda x : \" \".join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c648c986",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.931562Z",
          "start_time": "2022-10-17T14:30:47.921000Z"
        },
        "id": "c648c986"
      },
      "outputs": [],
      "source": [
        "df_visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4368e7a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:47.937379Z",
          "start_time": "2022-10-17T14:30:47.933004Z"
        },
        "id": "b4368e7a"
      },
      "outputs": [],
      "source": [
        "def bag_of_words (texts) :\n",
        "    data = texts\n",
        "    cv = CountVectorizer(min_df = 200).fit(data)\n",
        "    bow = cv.transform(data)\n",
        "    \n",
        "   # print (\"Taille : \",  len (cv.vocabulary_))\n",
        "   # print (\"Contenu : \",  cv.vocabulary_) # too long\n",
        "    \n",
        "   # Nombre de lignes et de colonnes de la matrice via Bag Of Words :\n",
        "   # print(bow.toarray().shape)\n",
        "    \n",
        "    data = pd.DataFrame.from_dict(cv.vocabulary_, orient='index',\n",
        "                       columns=['Frequency'])\n",
        "    data = data.sort_values(by=['Frequency'], ascending = False)\n",
        "    data = data[data['Frequency']>200]\n",
        "    \n",
        "    data['percent'] = round((data['Frequency'])*100/ data['Frequency'].sum(),2)\n",
        "    \n",
        "    return(data, bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9c36bb2",
      "metadata": {
        "id": "f9c36bb2"
      },
      "source": [
        "### Création d'un DataFrame de visualisation + une matrice :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fadd495",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:48.677285Z",
          "start_time": "2022-10-17T14:30:47.938704Z"
        },
        "id": "0fadd495"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "data_bow,bow = bag_of_words(df_visualisation[\"Corpus\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f87b889",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:48.680618Z",
          "start_time": "2022-10-17T14:30:48.678373Z"
        },
        "id": "4f87b889"
      },
      "outputs": [],
      "source": [
        "print(\"Nombres de questions pour le BOW:\", bow.shape[0])\n",
        "print(\"Nombres de tags uniques pour le BOW :\", bow.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a064305",
      "metadata": {
        "id": "0a064305"
      },
      "source": [
        "#### Visualisation : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d6c56b0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:48.689540Z",
          "start_time": "2022-10-17T14:30:48.681545Z"
        },
        "id": "2d6c56b0"
      },
      "outputs": [],
      "source": [
        "data_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228c3598",
      "metadata": {
        "id": "228c3598"
      },
      "source": [
        "### Vectorisation :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd40d8cf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:49.141288Z",
          "start_time": "2022-10-17T14:30:48.690669Z"
        },
        "id": "bd40d8cf"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "cv = CountVectorizer(min_df = 200)\n",
        "data_bow_2 = cv.fit_transform(df_visualisation[\"Corpus\"])\n",
        "data_bow_vec = pd.DataFrame(data_bow_2.toarray(), columns=cv.get_feature_names_out())\n",
        "data_bow_vec.index = df_final.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04db51ba",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:49.160872Z",
          "start_time": "2022-10-17T14:30:49.142257Z"
        },
        "id": "04db51ba"
      },
      "outputs": [],
      "source": [
        "data_bow_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ac9616",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:49.219703Z",
          "start_time": "2022-10-17T14:30:49.161888Z"
        },
        "id": "e0ac9616"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "score_Sparsicity_bow = data_bow_2.todense()\n",
        "print(\"Sparsicity: \", '\\033[1m'+ str((((score_Sparsicity_bow > 0).sum()/score_Sparsicity_bow.size)*100).round(2)) + '\\033[0m' , \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70f24241",
      "metadata": {
        "id": "70f24241"
      },
      "source": [
        "Afficher la Sparsicity (sous forme de nombre ou de proportion) d'une matrice.\n",
        "\n",
        "Par exemple, . 99% de  Sparsicity signifie que 99 % des valeurs sont nulles. De même, une Sparsicity de 0 signifie que la matrice est entièrement dense."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "841de5c2",
      "metadata": {
        "id": "841de5c2"
      },
      "source": [
        "## TF-IDF :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3458d19",
      "metadata": {
        "id": "a3458d19"
      },
      "source": [
        "La formule du tf-Idf est  : __poids = fréquence du terme * indicateur similarité__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ee37a1a",
      "metadata": {
        "id": "2ee37a1a"
      },
      "source": [
        "__Pour extraire les informations on utilise :__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a47f4da1",
      "metadata": {
        "id": "a47f4da1"
      },
      "source": [
        "__NER (Named Entity Recognition) :__ reconnaître des personnes, endroits, entreprises, etc.\n",
        "\n",
        "__Extraction de relations :__ essayer d'extraire des relations sémantiques entre différents termes du texte. Par exemple, des relations familiales (\"Marie est l'enfant de Patrick\") spatiales (\"Le piano est devant la fenêtre\"), etc. Ces informations peuvent ensuite être stockées dans une base de données relationnelles ou un graphe.\n",
        "\n",
        "__Extraction d'événements :__ extraire des actions qui arrivent à nos entités. Par exemple \"le cours de l'action X a augmenté de 5%\" ou bien \"le président à déclaré X dans son discours\"\n",
        "\n",
        "__POS Tagging (Part-of-Speech Tagging) :__ représente les méthodes qui récupèrent la nature grammatical des mots d’une phrase - nom, verbe, adjectif, etc. Ce sont des propriété qui peuvent servir de caractéristiques utile lors de la création de certains modèles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8421830",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:49.228245Z",
          "start_time": "2022-10-17T14:30:49.224977Z"
        },
        "id": "a8421830"
      },
      "outputs": [],
      "source": [
        "def Tfidf (texts) :\n",
        "    data = texts\n",
        "    tf = TfidfVectorizer(min_df = 200).fit(data) # on choisit de prendre que les mots avec 200 itérations\n",
        "    idf = tf.transform(texts)\n",
        "    \n",
        "    #print (\"Taille : \",  len (tf.vocabulary_))\n",
        "    # print (\"Contenu : \",  tf.vocabulary_) # too long\n",
        "    \n",
        "    # Nombre de lignes et de colonnes de la matrice via Bag Of Words :\n",
        "    #print(idf.toarray().shape)\n",
        "    \n",
        "    data = pd.DataFrame.from_dict(tf.vocabulary_, orient='index',\n",
        "                       columns=['Frequency'])\n",
        "    data = data.sort_values(by=['Frequency'], ascending = False)\n",
        "    data = data[data['Frequency']>200]\n",
        "    \n",
        "    data['percent'] = round((data['Frequency']*100)/ data['Frequency'].sum(),2)\n",
        "    \n",
        "    return(data,idf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd6db0e1",
      "metadata": {
        "id": "fd6db0e1"
      },
      "source": [
        "### Création d'un DataFrame de visualisation + une matrice :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca2dabcf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:49.955002Z",
          "start_time": "2022-10-17T14:30:49.229327Z"
        },
        "id": "ca2dabcf"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "Data_idf,idf = Tfidf(df_visualisation[\"Corpus\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca6b18d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:49.958164Z",
          "start_time": "2022-10-17T14:30:49.956115Z"
        },
        "id": "5ca6b18d"
      },
      "outputs": [],
      "source": [
        "print(\"Nombres de questions pour le TF-IDF :\", idf.shape[0])\n",
        "print(\"Nombres de tags uniques pour le TF-IDF :\", idf.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cf34f54",
      "metadata": {
        "id": "6cf34f54"
      },
      "source": [
        "#### Visualisation :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4d37fe",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:49.965476Z",
          "start_time": "2022-10-17T14:30:49.959112Z"
        },
        "id": "6d4d37fe"
      },
      "outputs": [],
      "source": [
        "Data_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e05b21f",
      "metadata": {
        "id": "1e05b21f"
      },
      "source": [
        "### Vectorisation :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d5e6ce2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:50.027840Z",
          "start_time": "2022-10-17T14:30:49.966548Z"
        },
        "id": "4d5e6ce2"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfTransformer()\n",
        "data_tfidf = tfidf.fit_transform(bow)\n",
        "data_tfidf_vec = pd.DataFrame(data_tfidf.toarray(), columns=cv.get_feature_names_out())\n",
        "data_tfidf_vec.index = df_final.index\n",
        "data_tfidf_vec.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0928d92",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:50.084588Z",
          "start_time": "2022-10-17T14:30:50.030618Z"
        },
        "id": "c0928d92"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "score_Sparsicity_tfidf = data_tfidf.todense()\n",
        "print(\"Sparsicity: \", '\\033[1m'+ str((((score_Sparsicity_tfidf > 0).sum()/score_Sparsicity_tfidf.size)*100).round(2)) + '\\033[0m' , \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d148fb55",
      "metadata": {
        "id": "d148fb55"
      },
      "source": [
        "On a donc 2.29% de données avec un 0 dans notre tf-idf."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2555e68",
      "metadata": {
        "id": "f2555e68"
      },
      "source": [
        "## ACP :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b0d2b89",
      "metadata": {
        "id": "1b0d2b89"
      },
      "source": [
        "Le code provient d'un cours d'OpenClassrooms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d82647db",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:50.527044Z",
          "start_time": "2022-10-17T14:30:50.091488Z"
        },
        "id": "d82647db"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "vectorizer = TfidfVectorizer(min_df = 200)\n",
        "X = vectorizer.fit_transform(df_visualisation[\"Corpus\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9f6c63a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:50.542448Z",
          "start_time": "2022-10-17T14:30:50.528460Z"
        },
        "id": "b9f6c63a"
      },
      "outputs": [],
      "source": [
        "def display_circles(pcs, n_comp, pca, axis_ranks, labels=None, label_rotation=0, lims=None):\n",
        "    \"\"\"Display correlation circles, one for each factorial plane\"\"\"\n",
        "\n",
        "    # For each factorial plane\n",
        "    for d1, d2 in axis_ranks: \n",
        "        if d2 < n_comp:\n",
        "\n",
        "            # Initialise the matplotlib figure\n",
        "            fig, ax = plt.subplots(figsize=(10,10))\n",
        "\n",
        "            # Determine the limits of the chart\n",
        "            if lims is not None :\n",
        "                xmin, xmax, ymin, ymax = lims\n",
        "            elif pcs.shape[1] < 30 :\n",
        "                xmin, xmax, ymin, ymax = -1, 1, -1, 1\n",
        "            else :\n",
        "                xmin, xmax, ymin, ymax = min(pcs[d1,:]), max(pcs[d1,:]), min(pcs[d2,:]), max(pcs[d2,:])\n",
        "\n",
        "            # Add arrows\n",
        "            # If there are more than 30 arrows, we do not display the triangle at the end\n",
        "            if pcs.shape[1] < 30 :\n",
        "                plt.quiver(np.zeros(pcs.shape[1]), np.zeros(pcs.shape[1]),\n",
        "                   pcs[d1,:], pcs[d2,:], \n",
        "                   angles='xy', scale_units='xy', scale=1, color=\"grey\")\n",
        "                # (see the doc : https://matplotlib.org/api/_as_gen/matplotlib.pyplot.quiver.html)\n",
        "            else:\n",
        "                lines = [[[0,0],[x,y]] for x,y in pcs[[d1,d2]].T]\n",
        "                ax.add_collection(LineCollection(lines, axes=ax, alpha=.1, color='black'))\n",
        "            \n",
        "            # Display variable names\n",
        "            if labels is not None:  \n",
        "                for i,(x, y) in enumerate(pcs[[d1,d2]].T):\n",
        "                    if x >= xmin and x <= xmax and y >= ymin and y <= ymax :\n",
        "                        plt.text(x, y, labels[i], fontsize='14', ha='center', va='center', rotation=label_rotation, color=\"blue\", alpha=0.5)\n",
        "            \n",
        "            # Display circle\n",
        "            circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
        "            plt.gca().add_artist(circle)\n",
        "\n",
        "            # Define the limits of the chart\n",
        "            plt.xlim(xmin, xmax)\n",
        "            plt.ylim(ymin, ymax)\n",
        "        \n",
        "            # Display grid lines\n",
        "            plt.plot([-1, 1], [0, 0], color='grey', ls='--')\n",
        "            plt.plot([0, 0], [-1, 1], color='grey', ls='--')\n",
        "\n",
        "            # Label the axes, with the percentage of variance explained\n",
        "            plt.xlabel('PC{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n",
        "            plt.ylabel('PC{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n",
        "\n",
        "            plt.title(\"Correlation Circle (PC{} and PC{})\".format(d1+1, d2+1))\n",
        "            plt.show(block=False)\n",
        "        \n",
        "def display_factorial_planes(X_projected, n_comp, pca, axis_ranks, labels=None, alpha=1, illustrative_var=None):\n",
        "    '''Display a scatter plot on a factorial plane, one for each factorial plane'''\n",
        "\n",
        "    # For each factorial plane\n",
        "    for d1,d2 in axis_ranks:\n",
        "        if d2 < n_comp:\n",
        " \n",
        "            # Initialise the matplotlib figure      \n",
        "            fig = plt.figure(figsize=(7,6))\n",
        "        \n",
        "            # Display the points\n",
        "            if illustrative_var is None:\n",
        "                plt.scatter(X_projected[:, d1], X_projected[:, d2], alpha=alpha)\n",
        "            else:\n",
        "                illustrative_var = np.array(illustrative_var)\n",
        "                for value in np.unique(illustrative_var):\n",
        "                    selected = np.where(illustrative_var == value)\n",
        "                    plt.scatter(X_projected[selected, d1], X_projected[selected, d2], alpha=alpha, label=value)\n",
        "                plt.legend()\n",
        "\n",
        "            # Display the labels on the points\n",
        "            if labels is not None:\n",
        "                for i,(x,y) in enumerate(X_projected[:,[d1,d2]]):\n",
        "                    plt.text(x, y, labels[i],\n",
        "                              fontsize='14', ha='center',va='center') \n",
        "                \n",
        "            # Define the limits of the chart\n",
        "            boundary = np.max(np.abs(X_projected[:, [d1,d2]])) * 1.1\n",
        "            plt.xlim([-boundary,boundary])\n",
        "            plt.ylim([-boundary,boundary])\n",
        "        \n",
        "            # Display grid lines\n",
        "            plt.plot([-100, 100], [0, 0], color='grey', ls='--')\n",
        "            plt.plot([0, 0], [-100, 100], color='grey', ls='--')\n",
        "\n",
        "            # Label the axes, with the percentage of variance explained\n",
        "            plt.xlabel('PC{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n",
        "            plt.ylabel('PC{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n",
        "\n",
        "            plt.title(\"Projection of points (on PC{} and PC{})\".format(d1+1, d2+1))\n",
        "            #plt.show(block=False)\n",
        "   \n",
        "def display_scree_plot(pca):\n",
        "    '''Display a scree plot for the pca'''\n",
        "\n",
        "    scree = pca.explained_variance_ratio_*100\n",
        "    plt.bar(np.arange(len(scree))+1, scree)\n",
        "    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')\n",
        "    plt.xlabel(\"Number of principal components\")\n",
        "    plt.ylabel(\"Percentage explained variance\")\n",
        "    plt.title(\"Scree plot\")\n",
        "    plt.show(block=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "154d071f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:54.304691Z",
          "start_time": "2022-10-17T14:30:50.547280Z"
        },
        "id": "154d071f"
      },
      "outputs": [],
      "source": [
        "# constitution du dataset pour l'ACP\n",
        "df_acp = pd.DataFrame(data = X.toarray(),  \n",
        "                      columns = list(vectorizer.get_feature_names_out()))\n",
        "\n",
        "n_comp = 200\n",
        "scaler = StandardScaler()\n",
        "pca = PCA(n_components=n_comp)\n",
        "\n",
        "X = df_acp.values\n",
        "features = df_acp.columns\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "pca_components = pca.fit_transform(X_scaled)\n",
        "pcs = pca.components_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be1e6ad",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:57.608679Z",
          "start_time": "2022-10-17T14:30:54.322850Z"
        },
        "id": "7be1e6ad"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "PCA_decomposition = decomposition.PCA(n_components = 200)\n",
        "PCA_decomposition.fit(X_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc8ec6f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:57.613448Z",
          "start_time": "2022-10-17T14:30:57.609759Z"
        },
        "id": "7dc8ec6f"
      },
      "outputs": [],
      "source": [
        "print('\\033[1m'+ 'Le pourcentage de variance expliqué pour 200 composantes est de :' + '\\033[0m')\n",
        "print('')\n",
        "print((PCA_decomposition.explained_variance_ratio_)*100)\n",
        "print('')\n",
        "print(f\"Le pourcentage de variance expliqué cumulé pour 200 composantes est de :\", '\\033[1m'+ str(round((PCA_decomposition.explained_variance_ratio_.sum())*100,2)) +'\\033[0m', '%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c2df1dd",
      "metadata": {
        "id": "8c2df1dd"
      },
      "source": [
        "### Visualisation des dimensions :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13f5907b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:57.868635Z",
          "start_time": "2022-10-17T14:30:57.614466Z"
        },
        "id": "13f5907b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "display_scree_plot(pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a687088",
      "metadata": {
        "id": "6a687088"
      },
      "source": [
        "On peut voir qu'au fur et à mesure cela réduit, mais que le pourcentage de variance expliquée est relativement faible.."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7970797e",
      "metadata": {
        "id": "7970797e"
      },
      "source": [
        "### Cercle de corrélation :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c29526ae",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:58.565043Z",
          "start_time": "2022-10-17T14:30:57.871443Z"
        },
        "id": "c29526ae"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "display_circles(pcs, n_comp, pca, [(0,1)], labels = np.array(features))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef89d43c",
      "metadata": {
        "id": "ef89d43c"
      },
      "source": [
        "### Vectorisation de la PC1 et PC2 :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76c344b9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:58.753270Z",
          "start_time": "2022-10-17T14:30:58.565998Z"
        },
        "id": "76c344b9"
      },
      "outputs": [],
      "source": [
        "X_projected = pca.transform(X_scaled) \n",
        "\n",
        "plt.figure(figsize=(30, 30))\n",
        "display_factorial_planes(X_projected, n_comp, pca, [(0,1)], alpha = 0.1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f789a04",
      "metadata": {
        "id": "3f789a04"
      },
      "source": [
        "On peut voir ici que la PCA n'est pas pertinente, de ce fait on ne retiendra pas l'acp."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "393002b9",
      "metadata": {
        "id": "393002b9"
      },
      "source": [
        "## LDA :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fefccb4",
      "metadata": {
        "id": "8fefccb4"
      },
      "source": [
        "Hypothése de la LDA à confirmer :\n",
        "\n",
        "    - Chaque document du corpus est un ensemble de mots sans ordre (bag-of-words)\n",
        "    \n",
        "    - Chaque document n'aborde un certain nombre de thèmes dans différentes proportions qui lui sont propres p(θm)\n",
        "\n",
        "    - Chaque mot possède une distribution associée à chaque thème p(ϕk)\n",
        "    \n",
        "    - Zn représente le thème du mot Wn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f950e57",
      "metadata": {
        "id": "3f950e57"
      },
      "source": [
        "### lda opti pour le BOW :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ed65c1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:58.762774Z",
          "start_time": "2022-10-17T14:30:58.759325Z"
        },
        "id": "73ed65c1"
      },
      "outputs": [],
      "source": [
        "\"\"\"def lda_opti (texts) :\n",
        "\n",
        "    score = []\n",
        "    perplexity = []\n",
        "    N = [5, 6, 7, 8, 9, 10, 11, 12, 15, 18, 20, 30]\n",
        "    \n",
        "    for n_comp in N :\n",
        "        \n",
        "        lda_model = LatentDirichletAllocation(random_state=0, n_components= n_comp, verbose = 2) # no random\n",
        "        lda_fit = lda_model.fit(texts)\n",
        "        lda_output = lda_fit.transform(texts)\n",
        "        lda_score =  lda_fit.score(texts)\n",
        "        score.append(lda_score)\n",
        "        #print(\"Le score de cohérence est de :\", score)\n",
        "        lda_perplexity =lda_fit.perplexity(texts)\n",
        "        perplexity.append(lda_perplexity)\n",
        "        #print(\"Le score de perplexité est de :\", perplexity)\n",
        "\n",
        "    return(score, perplexity)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b553a627",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:58.767364Z",
          "start_time": "2022-10-17T14:30:58.763884Z"
        },
        "id": "b553a627"
      },
      "outputs": [],
      "source": [
        "\"\"\"def lda_opti (texts) :\n",
        "\n",
        "    lda_model = LatentDirichletAllocation(random_state=0) # no random\n",
        "    score = []\n",
        "    perplexity = []\n",
        "    \n",
        "    # Hyperparameters :\n",
        "    params = { \n",
        "        'n_components': [5, 6, 7, 8, 9, 10, 11, 12, 15, 18, 20, 30], # number of component\n",
        "        'learning_decay': [0.75, 0.80, 0.85] # learning rate from online method\n",
        "    }\n",
        "\n",
        "    # GridSearchCV :\n",
        "    lda_search = GridSearchCV(lda_model,\n",
        "                              param_grid=params,\n",
        "                              #n_jobs=-1,\n",
        "                              cv=5,\n",
        "                              verbose=2\n",
        "                             )\n",
        "    \n",
        "    \n",
        "    lda_fit = lda_search.fit(texts) # fit data\n",
        "    lda_output = lda_fit.transform(texts) # tranform data\n",
        "    lda_score =  lda_fit.score(texts)\n",
        "    score.append(lda_score)\n",
        "    lda_perplexity =lda_fit.perplexity(texts)\n",
        "    perplexity.append(lda_perplexity)\n",
        "    \n",
        "    return(score, perplexity, lda_output)\"\"\"\n",
        "\n",
        "# Une méthode plus rapide a été utilisée."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50fc2a8c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:58.772163Z",
          "start_time": "2022-10-17T14:30:58.768489Z"
        },
        "id": "50fc2a8c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "%%time\n",
        "coherence_bow, perplexity_bow = lda_opti(bow)\n",
        "\n",
        "import pickle\n",
        "# Pour stock les données du lda bow :\n",
        "pickle.dump(coherence_bow, open('score_bow.pkl', 'wb'))\n",
        "pickle.dump(perplexity_bow, open('perplexity_bow.pkl', 'wb'))\n",
        "# XXX.to_csv(\"P5_bow_lda.csv\", index=False) # Cela permettra d'éviter de relancer le lda\n",
        "# Une méthode plus rapide a été utilisée.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35a3c87f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:30:58.777246Z",
          "start_time": "2022-10-17T14:30:58.773458Z"
        },
        "id": "35a3c87f"
      },
      "outputs": [],
      "source": [
        "\"\"\"%%time\n",
        "# Define Search Param\n",
        "params = {'n_components': [5, 6, 7, 8, 9, 10, 20, 30],\n",
        "          'learning_decay': [.5, .7, .9]\n",
        "          }\n",
        "\n",
        "# Init the Model\n",
        "lda = LatentDirichletAllocation(random_state=0)\n",
        "\n",
        "# Init Grid Search Class\n",
        "model = GridSearchCV(lda,\n",
        "                     param_grid=params,\n",
        "                     cv=5,\n",
        "                     verbose=2,\n",
        "                     n_jobs=-1,\n",
        "                     )\n",
        "\n",
        "# Do the Grid Search\n",
        "model.fit(bow)\n",
        "lda_output = model.transform(bow)\n",
        "\n",
        "# Modéle à choisir\n",
        "best_lda_model = model.best_estimator_\n",
        "\n",
        "# meilleure paramétres :\n",
        "print(\"Meilleurs paramétres : \", model.best_params_)\n",
        "\n",
        "# Score de cohérence :\n",
        "print(\"Meilleur Score de cohérence : \", model.best_score_)\n",
        "\n",
        "# Score de perplexité :\n",
        "print(\"Meilleur score de perplexité : \", best_lda_model.perplexity(bow))\n",
        "\n",
        "# A mettre en commentaire une fois le best parameter trouvé\n",
        "## Wall time: 17min 39s\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e971d210",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:33:15.713274Z",
          "start_time": "2022-10-17T14:30:58.778434Z"
        },
        "id": "e971d210"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Define Search Param\n",
        "params = {'n_components': [5],\n",
        "          'learning_decay': [.5]\n",
        "         }\n",
        "\n",
        "# Init the Model\n",
        "lda = LatentDirichletAllocation(random_state=0)\n",
        "\n",
        "# Init Grid Search Class\n",
        "model = GridSearchCV(lda,\n",
        "                     param_grid=params,\n",
        "                     cv=5,\n",
        "                     verbose=2,\n",
        "                     n_jobs=-1,\n",
        "                    )\n",
        "\n",
        "# Do the Grid Search\n",
        "model.fit(bow)\n",
        "lda_output = model.transform(bow)\n",
        "\n",
        "# Modéle à choisir\n",
        "best_lda_model = model.best_estimator_\n",
        "\n",
        "# Score de cohérence :\n",
        "print(\"Meilleur Score de cohérence : \", model.best_score_)\n",
        "\n",
        "# Score de perplexité :\n",
        "print(\"Meilleur score de perplexité : \", best_lda_model.perplexity(bow))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a17b35fe",
      "metadata": {
        "id": "a17b35fe"
      },
      "source": [
        "On a confirmation que le nombre de LDA optimal pour le BOW est 5."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff661fc1",
      "metadata": {
        "id": "ff661fc1"
      },
      "source": [
        "#### Visualisation : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a27d32be",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:33:15.718181Z",
          "start_time": "2022-10-17T14:33:15.714829Z"
        },
        "id": "a27d32be"
      },
      "outputs": [],
      "source": [
        "\"\"\"# Get Log Likelyhoods from Grid Search Output\n",
        "n_topics = [5, 6, 7, 8, 9, 10, 20, 30]\n",
        "\n",
        "log_likelyhoods_5 = [round(model.cv_results_['mean_test_score'][index]) for index, gscore in enumerate(\n",
        "    model.cv_results_['params']) if gscore['learning_decay'] == 0.5]\n",
        "\n",
        "\n",
        "log_likelyhoods_7 = [round(model.cv_results_['mean_test_score'][index]) for index, gscore in enumerate(\n",
        "    model.cv_results_['params']) if gscore['learning_decay'] == 0.7]\n",
        "\n",
        "log_likelyhoods_9 = [round(model.cv_results_['mean_test_score'][index]) for index, gscore in enumerate(\n",
        "    model.cv_results_['params']) if gscore['learning_decay'] == 0.9]\n",
        "\n",
        "# Show graph\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(n_topics, log_likelyhoods_5, label='0.5')\n",
        "plt.plot(n_topics, log_likelyhoods_7, label='0.7')\n",
        "plt.plot(n_topics, log_likelyhoods_9, label='0.9')\n",
        "plt.title(\"Choosing Optimal LDA Model\")\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Log Likelyhood Scores\")\n",
        "plt.legend(title='Learning decay', loc='best')\n",
        "plt.show()\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b741c0",
      "metadata": {
        "id": "d8b741c0"
      },
      "source": [
        "#### Topic dominant :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2222e5f4",
      "metadata": {
        "id": "2222e5f4"
      },
      "source": [
        "Une partie du code provient de ce site :\n",
        "\n",
        "source : https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "519d8aef",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:33:19.439276Z",
          "start_time": "2022-10-17T14:33:15.719067Z"
        },
        "id": "519d8aef"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Create Document - Topic Matrix\n",
        "lda_output = best_lda_model.transform(bow)\n",
        "\n",
        "# column names\n",
        "topicnames = ['topic' + str(i) for i in range(best_lda_model.n_components)] # crée une liste de colonne  en fonction du nombre de composante n\n",
        "\n",
        "# index names\n",
        "docnames = ['Document' + str(i) for i in range(bow.toarray().shape[0])] # crée une liste de ligne en fonction du nombre de lignes de Bag of Words\n",
        "\n",
        "\n",
        "# Make the pandas dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
        "\n",
        "# Get dominant topic for each document\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "\n",
        "# Styling\n",
        "def color_green(val):\n",
        "    color = 'green' if val > .1 else 'black'\n",
        "    return 'color: {col}'.format(col=color)\n",
        "\n",
        "def make_bold(val):\n",
        "    weight = 700 if val > .1 else 400\n",
        "    return 'font-weight: {weight}'.format(weight=weight)\n",
        "\n",
        "# Apply Style\n",
        "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
        "df_document_topics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7965482a",
      "metadata": {
        "id": "7965482a"
      },
      "source": [
        "#### Review des topics en fonction des documents :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea4c40c7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:33:19.445668Z",
          "start_time": "2022-10-17T14:33:19.440217Z"
        },
        "id": "ea4c40c7"
      },
      "outputs": [],
      "source": [
        "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
        "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
        "df_topic_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caad7115",
      "metadata": {
        "id": "caad7115"
      },
      "source": [
        "#### Visualisation :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "392588ba",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:33:19.459157Z",
          "start_time": "2022-10-17T14:33:19.446775Z"
        },
        "id": "392588ba"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Topic-Keyword Matrix\n",
        "df_topic_keywords = pd.DataFrame(best_lda_model.components_)\n",
        "\n",
        "# Assign Column and Index\n",
        "df_topic_keywords.columns = cv.get_feature_names_out()\n",
        "df_topic_keywords.index = topicnames\n",
        "\n",
        "# View\n",
        "df_topic_keywords.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3ae2d0",
      "metadata": {
        "id": "7e3ae2d0"
      },
      "source": [
        "#### Visualisation du top des mots par topic : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d7470c3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:33:19.466542Z",
          "start_time": "2022-10-17T14:33:19.460435Z"
        },
        "id": "8d7470c3"
      },
      "outputs": [],
      "source": [
        "for topic in range(df_topic_keywords.shape[0]):\n",
        "    tmp = df_topic_keywords.iloc[topic]\n",
        "    print(f'Pour le Topic {topic+1}, les mots avec les plus hautes valeurs sont :')\n",
        "    print(tmp.nlargest(15))\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c371f47",
      "metadata": {
        "id": "9c371f47"
      },
      "source": [
        "### lda opti pour le IDF :"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut voir ici que nos topics comment à être plutôt bien défini"
      ],
      "metadata": {
        "id": "YA6k2l7Q_g_q"
      },
      "id": "YA6k2l7Q_g_q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f25dda",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:33:19.470586Z",
          "start_time": "2022-10-17T14:33:19.467619Z"
        },
        "id": "d9f25dda"
      },
      "outputs": [],
      "source": [
        "\"\"\"%%time\n",
        "# Define Search Param\n",
        "params = {'n_components': [5, 6, 7, 8, 9, 10, 20, 30],\n",
        "          'learning_decay': [.5, .7, .9]\n",
        "          }\n",
        "\n",
        "# Init the Model\n",
        "lda_idf = LatentDirichletAllocation(random_state=0)\n",
        "\n",
        "# Init Grid Search Class\n",
        "model_idf = GridSearchCV(lda_idf,\n",
        "                     param_grid=params,\n",
        "                     cv=5,\n",
        "                     verbose=2,\n",
        "                     #n_jobs=-1,\n",
        "                     )\n",
        "\n",
        "# Do the Grid Search\n",
        "model_idf.fit(idf)\n",
        "lda_output = model_idf.transform(idf)\n",
        "\n",
        "# Modéle à choisir\n",
        "best_lda_model_idf = model_idf.best_estimator_\n",
        "\n",
        "# meilleure paramétres :\n",
        "print(\"Meilleurs paramétres : \", model_idf.best_params_)\n",
        "\n",
        "# Score de cohérence :\n",
        "print(\"Meilleur Score de cohérence : \", model_idf.best_score_)\n",
        "\n",
        "# Score de perplexité :\n",
        "print(\"Meilleur score de perplexité : \", best_lda_model_idf.perplexity(idf))\n",
        "\n",
        "# A mettre en commentaire une fois le best parameter trouvé\n",
        "## Wall time: 50min 43s\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae2a85d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:37.453048Z",
          "start_time": "2022-10-17T14:33:19.471726Z"
        },
        "id": "dae2a85d"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Define Search Param\n",
        "params = {'n_components': [5],\n",
        "          'learning_decay': [.5]\n",
        "          }\n",
        "\n",
        "# Init the Model\n",
        "lda_idf = LatentDirichletAllocation(random_state=0)\n",
        "\n",
        "# Init Grid Search Class\n",
        "model_idf = GridSearchCV(lda_idf,\n",
        "                     param_grid=params,\n",
        "                     cv=5,\n",
        "                     verbose=2,\n",
        "                     #n_jobs=-1,\n",
        "                     )\n",
        "\n",
        "# Do the Grid Search\n",
        "model_idf.fit(idf)\n",
        "lda_output = model_idf.transform(idf)\n",
        "\n",
        "# Modéle à choisir\n",
        "best_lda_model_idf = model_idf.best_estimator_\n",
        "\n",
        "# meilleure paramétres :\n",
        "print(\"Meilleurs paramétres : \", model_idf.best_params_)\n",
        "\n",
        "# Score de cohérence :\n",
        "print(\"Meilleur Score de cohérence : \", model_idf.best_score_)\n",
        "\n",
        "# Score de perplexité :\n",
        "print(\"Meilleur score de perplexité : \", best_lda_model_idf.perplexity(idf))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a006c33a",
      "metadata": {
        "id": "a006c33a"
      },
      "source": [
        "#### Topic dominant :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50c5867b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:41.648093Z",
          "start_time": "2022-10-17T14:36:37.453999Z"
        },
        "id": "50c5867b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Create Document - Topic Matrix\n",
        "lda_output = best_lda_model_idf.transform(bow)\n",
        "\n",
        "# column names\n",
        "topicnames = ['topic' + str(i) for i in range(best_lda_model_idf.n_components)] # crée une liste de colonne  en fonction du nombre de composante n\n",
        "\n",
        "# index names\n",
        "docnames = ['Document' + str(i) for i in range(idf.toarray().shape[0])] # crée une liste de ligne en fonction du nombre de lignes de Bag of Words\n",
        "\n",
        "\n",
        "# Make the pandas dataframe\n",
        "df_document_topic_2 = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
        "\n",
        "# Get dominant topic for each document\n",
        "dominant_topic_2 = np.argmax(df_document_topic_2.values, axis=1)\n",
        "df_document_topic_2['dominant_topic'] = dominant_topic_2\n",
        "\n",
        "# Styling\n",
        "def color_green(val):\n",
        "    color = 'green' if val > .1 else 'black'\n",
        "    return 'color: {col}'.format(col=color)\n",
        "\n",
        "def make_bold(val):\n",
        "    weight = 700 if val > .1 else 400\n",
        "    return 'font-weight: {weight}'.format(weight=weight)\n",
        "\n",
        "# Apply Style\n",
        "df_document_topic_2 = df_document_topic_2.head(15).style.applymap(color_green).applymap(make_bold)\n",
        "df_document_topic_2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06d3cf03",
      "metadata": {
        "id": "06d3cf03"
      },
      "source": [
        "#### Recherche des topics en fonction des documents :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19375cfc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:41.653521Z",
          "start_time": "2022-10-17T14:36:41.648991Z"
        },
        "id": "19375cfc"
      },
      "outputs": [],
      "source": [
        "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
        "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
        "df_topic_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9fd9659",
      "metadata": {
        "id": "e9fd9659"
      },
      "source": [
        "#### Visualisation :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe17dc1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:41.665978Z",
          "start_time": "2022-10-17T14:36:41.654486Z"
        },
        "id": "3fe17dc1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Topic-Keyword Matrix\n",
        "df_topic_keywords_2 = pd.DataFrame(best_lda_model_idf.components_)\n",
        "\n",
        "# Assign Column and Index\n",
        "df_topic_keywords_2.columns = cv.get_feature_names_out()\n",
        "df_topic_keywords_2.index = topicnames\n",
        "\n",
        "# View\n",
        "df_topic_keywords_2.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a01d9e0f",
      "metadata": {
        "id": "a01d9e0f"
      },
      "source": [
        "#### Visualisation du top des mots par topic : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a7f28f5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:41.672740Z",
          "start_time": "2022-10-17T14:36:41.667087Z"
        },
        "id": "7a7f28f5"
      },
      "outputs": [],
      "source": [
        "for topic in range(df_topic_keywords_2.shape[0]):\n",
        "    tmp = df_topic_keywords_2.iloc[topic]\n",
        "    print(f'Pour le Topic {topic+1}, les mots avec les plus hautes valeurs sont :')\n",
        "    print(tmp.nlargest(15))\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut voir ici que les topics commencent également à être bien identifiés."
      ],
      "metadata": {
        "id": "wCf09IZTAC5x"
      },
      "id": "wCf09IZTAC5x"
    },
    {
      "cell_type": "markdown",
      "id": "41e39041",
      "metadata": {
        "id": "41e39041"
      },
      "source": [
        "## NMF :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6390fc8",
      "metadata": {
        "id": "f6390fc8"
      },
      "source": [
        "En algèbre linéaire et en analyse à plusieurs variables, la factorisation matricielle non négative est un groupe d’algorithmes qui permet de factoriser une matrice V en deux matrices (W et H) qui ne contiennent que des valeurs positives ou nulles et dont le produit est proche de V.\n",
        "\n",
        "source : https://datafranca.org/wiki/Factorisation_matricielle_non_négative\n",
        "source : https://predictivehacks.com/topic-modelling-with-nmf-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60c15f9c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:41.678623Z",
          "start_time": "2022-10-17T14:36:41.676796Z"
        },
        "id": "60c15f9c"
      },
      "outputs": [],
      "source": [
        "top_topics = 5\n",
        "X = idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d12f948",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:41.950067Z",
          "start_time": "2022-10-17T14:36:41.679473Z"
        },
        "id": "6d12f948"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Create an NMF instance: model\n",
        "# the 10 components will be the topics\n",
        "model_nmf = NMF(n_components=top_topics, random_state= 0)\n",
        " \n",
        "# Fit the model to TF-IDF\n",
        "model_nmf.fit(X)\n",
        " \n",
        "# Transform the TF-IDF: nmf_features\n",
        "nmf_features = model_nmf.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4674e197",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:41.956946Z",
          "start_time": "2022-10-17T14:36:41.951437Z"
        },
        "id": "4674e197"
      },
      "outputs": [],
      "source": [
        "print(f\"Shape de X :\")\n",
        "display(X.shape)\n",
        "print('')\n",
        "print(f\"Shape des features de NMF :\")\n",
        "display(nmf_features.shape)\n",
        "print('')\n",
        "print(f\"Shape des composantes de NMF :\")\n",
        "display(model_nmf.components_.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac00c19f",
      "metadata": {
        "id": "ac00c19f"
      },
      "source": [
        "#### Visualisation du DataFrame :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42d0cbf5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:41.969710Z",
          "start_time": "2022-10-17T14:36:41.958070Z"
        },
        "id": "42d0cbf5"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame: components_df\n",
        "components_df = pd.DataFrame(model_nmf.components_, columns=cv.get_feature_names_out())\n",
        "components_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26dc2c98",
      "metadata": {
        "id": "26dc2c98"
      },
      "source": [
        "#### Visualisation du top des mots par topic : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c4f0647",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:41.976409Z",
          "start_time": "2022-10-17T14:36:41.971177Z"
        },
        "id": "4c4f0647"
      },
      "outputs": [],
      "source": [
        "for topic in range(components_df.shape[0]):\n",
        "    tmp = components_df.iloc[topic]\n",
        "    print(f'Pour le Topic {topic+1}, les mots avec les plus hautes valeurs sont :')\n",
        "    print(tmp.nlargest(10))\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut commencer à voir ici que chaque Topic commence à être bien défini en fonction du type de demande."
      ],
      "metadata": {
        "id": "qDLeuDW2f_lz"
      },
      "id": "qDLeuDW2f_lz"
    },
    {
      "cell_type": "markdown",
      "id": "723eac11",
      "metadata": {
        "id": "723eac11"
      },
      "source": [
        "Ce lien m'a fortement aidé : https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial/notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bebf4872",
      "metadata": {
        "id": "bebf4872"
      },
      "source": [
        "# Approche supervisée :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "799bbe5e",
      "metadata": {
        "id": "799bbe5e"
      },
      "source": [
        "## Création de colonne pour le futur X et y :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "648d32b0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:41.987396Z",
          "start_time": "2022-10-17T14:36:41.977565Z"
        },
        "id": "648d32b0"
      },
      "outputs": [],
      "source": [
        "df_visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76bc5aae",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:42.006133Z",
          "start_time": "2022-10-17T14:36:41.988686Z"
        },
        "id": "76bc5aae"
      },
      "outputs": [],
      "source": [
        "df_modellisation = df_visualisation[['corpus_preprocessing','tags_preprocessing']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2dfb3ab",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:42.037507Z",
          "start_time": "2022-10-17T14:36:42.007329Z"
        },
        "id": "d2dfb3ab"
      },
      "outputs": [],
      "source": [
        "df_modellisation['corpus_finish'] = df_modellisation['corpus_preprocessing'].apply(lambda x : \" \".join(x))\n",
        "df_modellisation['tags_finish'] = df_modellisation['tags_preprocessing'].apply(lambda x : \" \".join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fb272c6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:42.048673Z",
          "start_time": "2022-10-17T14:36:42.038743Z"
        },
        "id": "2fb272c6"
      },
      "outputs": [],
      "source": [
        "df_modellisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_modellisation.to_csv(\"/content/drive/My Drive/Colab Notebooks/Projet_5/P5_yyy.csv\", index=True) # Cela permettra d'éviter d'attendre de relancer le notebook."
      ],
      "metadata": {
        "id": "4vdaKYptfY2k"
      },
      "id": "4vdaKYptfY2k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "db815d21",
      "metadata": {
        "id": "db815d21"
      },
      "source": [
        "## Reduction du nombre de tags :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed98abc0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:42.052002Z",
          "start_time": "2022-10-17T14:36:42.049899Z"
        },
        "id": "ed98abc0"
      },
      "outputs": [],
      "source": [
        "from nltk import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cdb6715",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:42.068275Z",
          "start_time": "2022-10-17T14:36:42.053098Z"
        },
        "id": "9cdb6715"
      },
      "outputs": [],
      "source": [
        "frequence = FreqDist(df_modellisation['tags_finish'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008d2ffd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:42.076023Z",
          "start_time": "2022-10-17T14:36:42.069324Z"
        },
        "id": "008d2ffd"
      },
      "outputs": [],
      "source": [
        "# on stock un dictionnaire du nombre de tags que l'on souhaite garder\n",
        "from collections import Counter\n",
        "top_50 = dict(Counter(frequence).most_common(50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3585a80c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:42.079947Z",
          "start_time": "2022-10-17T14:36:42.077208Z"
        },
        "id": "3585a80c"
      },
      "outputs": [],
      "source": [
        "top_50_tags = []\n",
        "for key,value in top_50.items() :\n",
        "    top_50_tags.append(key)\n",
        "# garder que les clefs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62084063",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:42.246220Z",
          "start_time": "2022-10-17T14:36:42.081023Z"
        },
        "id": "62084063"
      },
      "outputs": [],
      "source": [
        "df_modellisation['tags_final'] = df_modellisation['tags_preprocessing'].apply(lambda x : [element for element in x if element in top_50_tags ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa93320",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:42.873844Z",
          "start_time": "2022-10-17T14:36:42.259099Z"
        },
        "id": "daa93320"
      },
      "outputs": [],
      "source": [
        "liste_index = []\n",
        "for i,l in df_modellisation.iterrows() :\n",
        "    if len(l['tags_final']) == 0 :\n",
        "        liste_index.append(i)\n",
        "print(f\"Le nombre de lignes qui seront supprimés est de :\", len(liste_index))\n",
        "print(\"fLe nombre de ligne du dataframe avant suppression est de :\", df_modellisation.shape[0])\n",
        "df_modellisation.drop(liste_index, inplace = True) # suppression de la liste\n",
        "print(\"fLe nombre de ligne du dataframe aprés suppression est de :\", df_modellisation.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_modellisation"
      ],
      "metadata": {
        "id": "8rYRdsBQlPHd"
      },
      "id": "8rYRdsBQlPHd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e76f460f",
      "metadata": {
        "id": "e76f460f"
      },
      "source": [
        "# CSV pour les algo : "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Styling\n",
        "def color_yellow(val):\n",
        "    color = 'yellow' if val > .2 else 'black'\n",
        "    return 'color: {col}'.format(col=color)\n",
        "\n",
        "def make_bold(val):\n",
        "    weight = 700 if val > .2 else 700\n",
        "    return 'font-weight: {weight}'.format(weight=weight)"
      ],
      "metadata": {
        "id": "ahrJ2QD9kXkJ"
      },
      "id": "ahrJ2QD9kXkJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89985f76",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:43.105328Z",
          "start_time": "2022-10-17T14:36:42.878901Z"
        },
        "id": "89985f76"
      },
      "outputs": [],
      "source": [
        "#df_modellisation.to_csv(\"/content/drive/My Drive/Colab Notebooks/Projet_5/P5_xxx.csv\", index=True, encoding='utf-8',na_rep='NULL') # Cela permettra d'éviter d'attendre de relancer le notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data_test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Projet_5/P5_test.csv\")"
      ],
      "metadata": {
        "id": "EHHTLr01olCv"
      },
      "id": "EHHTLr01olCv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "936a95cc",
      "metadata": {
        "id": "936a95cc"
      },
      "source": [
        "## Algorithme utilisant le BOW : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90d9a09b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:43.711124Z",
          "start_time": "2022-10-17T14:36:43.106261Z"
        },
        "id": "90d9a09b"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(min_df = 200)\n",
        "corpus_bow = vectorizer.fit_transform(df_modellisation['corpus_finish'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae819b44",
      "metadata": {
        "id": "ae819b44"
      },
      "source": [
        "### Train test via BOW :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2c20fd9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:44.419773Z",
          "start_time": "2022-10-17T14:36:44.417727Z"
        },
        "id": "b2c20fd9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_modellisation['tags_final']\n",
        "multi_lab = MultiLabelBinarizer(classes= top_50_tags)\n",
        "Y = multi_lab.fit_transform(y)\n",
        "\n",
        "print(\"Affichage des classes du multilabel :\")\n",
        "display(multi_lab.classes_)"
      ],
      "metadata": {
        "id": "invyV6k-VYPO"
      },
      "id": "invyV6k-VYPO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ecc1396",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:44.427969Z",
          "start_time": "2022-10-17T14:36:44.420552Z"
        },
        "id": "1ecc1396"
      },
      "outputs": [],
      "source": [
        "X = corpus_bow # a modifier par tfidf et par wordtovec\n",
        "y = Y\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"model_metrics['Regression_logistique']  = {'Accuracy': round(metrics.accuracy_score(y_test, y_pred), 2) ,\n",
        "                  'Hamming loss' : round(metrics.hamming_loss(y_test, y_pred), 2),\n",
        "                  'Jaccard_score' : round(metrics.jaccard_score(y_test, y_pred, average=\"weighted\"), 2),\n",
        "                  'f1_macro_score' : round(metrics.f1_score(y_test, y_pred, average='macro'), 2),\n",
        "                  'f1_micro_score' : round(metrics.f1_score(y_test, y_pred, average='micro'), 2),\n",
        "                  'Recall_micro_score' : round(metrics.f1_score(y_test, y_pred, average='micro'), 2),\n",
        "                  'Recall_macro_score' : round(metrics.f1_score(y_test, y_pred, average='macro'), 2)\n",
        "                 }\n",
        "model_metrics\"\"\"\n",
        "# mis en fonction"
      ],
      "metadata": {
        "id": "ZNil_LGn-nhO"
      },
      "id": "ZNil_LGn-nhO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Création d'une liste pour les scores des métrics :"
      ],
      "metadata": {
        "id": "hzhxwfyWxoW9"
      },
      "id": "hzhxwfyWxoW9"
    },
    {
      "cell_type": "code",
      "source": [
        "model_metrics_bow = {} # Garde en mémoire les scores"
      ],
      "metadata": {
        "id": "JM7VSDeH-QsE"
      },
      "id": "JM7VSDeH-QsE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "182890e6",
      "metadata": {
        "id": "182890e6"
      },
      "source": [
        "### Regression logistique :"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_log (X_train, y_train, X_test) :\n",
        "  \n",
        "  model_svm = OneVsRestClassifier(LogisticRegression())\n",
        "  model_svm.fit(X_train, y_train)\n",
        "  y_pred = model_svm.predict(X_test)\n",
        "  \n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "CQFQfcr3gvsv"
      },
      "id": "CQFQfcr3gvsv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = regression_log (X_train, y_train, X_test)\n",
        "#multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_bow, \"reg_log\")"
      ],
      "metadata": {
        "id": "D2NQ5lhiPYaF"
      },
      "id": "D2NQ5lhiPYaF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17cebab6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:36:52.621848Z",
          "start_time": "2022-10-17T14:36:44.615127Z"
        },
        "id": "17cebab6"
      },
      "outputs": [],
      "source": [
        "\"\"\"%%time\n",
        "model_log = OneVsRestClassifier(LogisticRegression())\n",
        "model_log.fit(X_train, y_train)\n",
        "y_pred = model_log.predict(X_test)\n",
        "# Mis en fonction \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7341f77",
      "metadata": {
        "id": "a7341f77"
      },
      "source": [
        "### Random Forest :"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest (X_train, y_train, X_test) :\n",
        "\n",
        "  model_rf = OneVsRestClassifier(RandomForestClassifier())\n",
        "  model_rf.fit(X_train, y_train)\n",
        "  y_pred = model_rf.predict(X_test) \n",
        "  \n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "-lgyL_t4P7Sl"
      },
      "id": "-lgyL_t4P7Sl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = random_forest (X_train, y_train, X_test)\n",
        "#multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_bow, \"random_forest\")"
      ],
      "metadata": {
        "id": "FMEg1QoXQO2Q"
      },
      "id": "FMEg1QoXQO2Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c1dcbe",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:39:56.959953Z",
          "start_time": "2022-10-17T14:36:52.713623Z"
        },
        "scrolled": false,
        "id": "05c1dcbe"
      },
      "outputs": [],
      "source": [
        "\"\"\"%%time\n",
        "model_rf = OneVsRestClassifier(RandomForestClassifier())\n",
        "model_rf.fit(X_train, y_train)\n",
        "y_pred = model_rf.predict(X_test)\"\"\"\n",
        "# mis en fonction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e240b1",
      "metadata": {
        "id": "57e240b1"
      },
      "source": [
        "### Decision tree : "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decision_tree (X_train, y_train, X_test) :\n",
        "\n",
        "  model_tree = OneVsRestClassifier(DecisionTreeClassifier())\n",
        "  model_tree.fit(X_train, y_train)\n",
        "  y_pred = model_tree.predict(X_test) \n",
        "  \n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "06gF7ZccQfNv"
      },
      "id": "06gF7ZccQfNv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = decision_tree (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_bow, \"decision_tree\")"
      ],
      "metadata": {
        "id": "5S6Ju9nOQfPe"
      },
      "id": "5S6Ju9nOQfPe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e56c660f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:40:15.018270Z",
          "start_time": "2022-10-17T14:39:57.059101Z"
        },
        "id": "e56c660f"
      },
      "outputs": [],
      "source": [
        "\"\"\"%%time\n",
        "model_tree = OneVsRestClassifier(DecisionTreeClassifier())\n",
        "model_tree.fit(X_train, y_train)\n",
        "y_pred = model_tree.predict(X_test)\"\"\"\n",
        "# Mis en fonction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a14d8315",
      "metadata": {
        "id": "a14d8315"
      },
      "source": [
        "### KNN : "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def KNeighbors (X_train, y_train, X_test) :\n",
        "\n",
        "  model_knn = OneVsRestClassifier(KNeighborsClassifier())\n",
        "  model_knn.fit(X_train, y_train)\n",
        "  y_pred = model_knn.predict(X_test)\n",
        "  \n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "blD_EWvpQ_b1"
      },
      "id": "blD_EWvpQ_b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = KNeighbors (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_bow, \"knn\")"
      ],
      "metadata": {
        "id": "OKCfWhwVQ_eA"
      },
      "id": "OKCfWhwVQ_eA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fa7cb0f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:42:46.996591Z",
          "start_time": "2022-10-17T14:40:15.115499Z"
        },
        "id": "5fa7cb0f"
      },
      "outputs": [],
      "source": [
        "\"\"\"%%time\n",
        "model_knn = OneVsRestClassifier(KNeighborsClassifier())\n",
        "model_knn.fit(X_train, y_train)\n",
        "y_pred = model_knn.predict(X_test)\"\"\"\n",
        "# Mis en fonction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "467ea4d3",
      "metadata": {
        "id": "467ea4d3"
      },
      "source": [
        "### Xgboost :"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def xgboost (X_train, y_train, X_test) :\n",
        "\n",
        "  model_xgb = OneVsRestClassifier(XGBRegressor())\n",
        "  model_xgb.fit(X_train, y_train)\n",
        "  y_pred = model_xgb.predict(X_test)  \n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "n1hQGcxTRbVc"
      },
      "id": "n1hQGcxTRbVc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = xgboost (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_bow, \"xgboost\")"
      ],
      "metadata": {
        "id": "_OAQjFThRbXq"
      },
      "id": "_OAQjFThRbXq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72d0b019",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:43:41.960219Z",
          "start_time": "2022-10-17T14:42:47.097317Z"
        },
        "id": "72d0b019"
      },
      "outputs": [],
      "source": [
        "\"\"\"%%time\n",
        "model_xgb = OneVsRestClassifier(XGBRegressor())\n",
        "model_xgb.fit(X_train, y_train)\n",
        "y_pred = model_xgb.predict(X_test)\"\"\"\n",
        "# mis en fonction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting :"
      ],
      "metadata": {
        "id": "cpcL10knxwTZ"
      },
      "id": "cpcL10knxwTZ"
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_boost (X_train, y_train, X_test) :\n",
        "  \n",
        "  model_svm = OneVsRestClassifier(GradientBoostingClassifier())\n",
        "  model_svm.fit(X_train, y_train)\n",
        "  y_pred = model_svm.predict(X_test)\n",
        "  \n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "lc76CFGHxu5y"
      },
      "id": "lc76CFGHxu5y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = gradient_boost (X_train, y_train, X_test)\n",
        "# model_svc = multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_bow, \"gradient_boost\")"
      ],
      "metadata": {
        "id": "1MsK-_W6yKJ8"
      },
      "id": "1MsK-_W6yKJ8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataframe des scores pour le BOW :"
      ],
      "metadata": {
        "id": "qFV-o0RLD_IT"
      },
      "id": "qFV-o0RLD_IT"
    },
    {
      "cell_type": "code",
      "source": [
        "score_bow = pd.DataFrame.from_dict(model_metrics_bow)\n",
        "# score_bow = score_bow.style.applymap(color_yellow).applymap(make_bold)\n",
        "print(\"-\"*100)\n",
        "print(\"-\"*44 + f\"Via le BOW :\" + \"-\"*44)\n",
        "print(\"-\"*100)\n",
        "display(score_bow)"
      ],
      "metadata": {
        "id": "AQfrY4Y_ECHA"
      },
      "id": "AQfrY4Y_ECHA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_bow.to_csv(\"/content/drive/My Drive/Colab Notebooks/Projet_5/Resultat_score_bow.csv\", index=True) # Cela permettra d'éviter d'attendre de relancer le notebook."
      ],
      "metadata": {
        "id": "3bkJ07nWAobd"
      },
      "id": "3bkJ07nWAobd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "34c0fc38",
      "metadata": {
        "id": "34c0fc38"
      },
      "source": [
        "## Algorithme utilisant le tf-idf :"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_metrics_tfidf = {}"
      ],
      "metadata": {
        "id": "86bXSkihiZRe"
      },
      "id": "86bXSkihiZRe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "298996ae",
      "metadata": {
        "id": "298996ae"
      },
      "source": [
        "### Train test via tf-idf :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b35c056",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:43:58.666808Z",
          "start_time": "2022-10-17T14:43:58.377948Z"
        },
        "id": "7b35c056"
      },
      "outputs": [],
      "source": [
        "tf_idf_vec = TfidfVectorizer(min_df = 200)\n",
        "corpus_idf = tf_idf_vec.fit_transform(df_modellisation['corpus_finish'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d56e25f5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:43:58.675242Z",
          "start_time": "2022-10-17T14:43:58.667772Z"
        },
        "id": "d56e25f5"
      },
      "outputs": [],
      "source": [
        "X = corpus_idf # a modifier par tfidf et par wordtovec\n",
        "y = Y\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e5bae8",
      "metadata": {
        "id": "e7e5bae8"
      },
      "source": [
        "### Regression Logistique :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a51708a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:44:03.544446Z",
          "start_time": "2022-10-17T14:44:03.452272Z"
        },
        "id": "0a51708a"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_pred = regression_log (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_tfidf, \"reg_log\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9191ffbf",
      "metadata": {
        "id": "9191ffbf"
      },
      "source": [
        "### Random Forest :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "830317e5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:48:28.739903Z",
          "start_time": "2022-10-17T14:48:28.637490Z"
        },
        "id": "830317e5"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_pred = random_forest (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_tfidf, \"random_forest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32518830",
      "metadata": {
        "id": "32518830"
      },
      "source": [
        "### Decision tree : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bea03de6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:49:23.635188Z",
          "start_time": "2022-10-17T14:49:23.541254Z"
        },
        "id": "bea03de6"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_pred = decision_tree (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_tfidf, \"decision_tree\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5bf5c17",
      "metadata": {
        "id": "e5bf5c17"
      },
      "source": [
        "### KNN : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4ef5074",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:51:36.521582Z",
          "start_time": "2022-10-17T14:51:36.428329Z"
        },
        "id": "a4ef5074"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_pred = KNeighbors (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_tfidf, \"knn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3469c53d",
      "metadata": {
        "id": "3469c53d"
      },
      "source": [
        "### Xgboost :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91812555",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-10-17T14:52:58.300685Z",
          "start_time": "2022-10-17T14:52:58.202137Z"
        },
        "id": "91812555"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_pred = xgboost (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_tfidf, \"xgboost\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting :"
      ],
      "metadata": {
        "id": "L9Six_xiyeFA"
      },
      "id": "L9Six_xiyeFA"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = gradient_boost (X_train, y_train, X_test)\n",
        "# model_svc = multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_tfidf, \"gradient_boost\")"
      ],
      "metadata": {
        "id": "3cA5SaEvyeKc"
      },
      "id": "3cA5SaEvyeKc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"score_tfidf = pd.DataFrame.from_dict(model_metrics_tfidf)\n",
        "score_tfidf = score_tfidf.style.applymap(color_yellow).applymap(make_bold)\"\"\""
      ],
      "metadata": {
        "id": "yAxDYX3YGLcn"
      },
      "id": "yAxDYX3YGLcn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_tfidf = pd.DataFrame.from_dict(model_metrics_tfidf)\n",
        "# score_tfidf = score_tfidf.style.applymap(color_yellow).applymap(make_bold)\n",
        "print(\"-\"*100)\n",
        "print(\"-\"*43 + f\"Via le TFIDF :\" + \"-\"*43)\n",
        "print(\"-\"*100)\n",
        "display(score_tfidf)"
      ],
      "metadata": {
        "id": "axArUBNR_5wd"
      },
      "id": "axArUBNR_5wd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataframe des scores pour le tf-idf :"
      ],
      "metadata": {
        "id": "oTsIP8rww39t"
      },
      "id": "oTsIP8rww39t"
    },
    {
      "cell_type": "code",
      "source": [
        "score_tfidf.to_csv(\"/content/drive/My Drive/Colab Notebooks/Projet_5/Resultat_score_tfidf.csv\") # Cela permettra d'éviter d'attendre de relancer le notebook."
      ],
      "metadata": {
        "id": "3gSeISXQAyQt"
      },
      "id": "3gSeISXQAyQt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6d45186a",
      "metadata": {
        "id": "6d45186a"
      },
      "source": [
        "## Algorithme utilisant le word2vec :"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connaître le nombre de mots max :"
      ],
      "metadata": {
        "id": "XnSO-9QGTs65"
      },
      "id": "XnSO-9QGTs65"
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour connaitre le max len :\n",
        "df_modellisation['length_corpus'] = df_modellisation['corpus_finish'].apply(lambda x : len(tokenize(x)))\n",
        "print(f\"Dans le corpus, le nombre de mots maximum est de : \", df_modellisation['length_corpus'].max())"
      ],
      "metadata": {
        "id": "zjzDhtjoTsL4"
      },
      "id": "zjzDhtjoTsL4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ae635360",
      "metadata": {
        "id": "ae635360"
      },
      "source": [
        "### Train test via word2vec :"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = df_modellisation['corpus_finish']\n",
        "corpus_count = 270"
      ],
      "metadata": {
        "id": "AFc2Lujycfym"
      },
      "id": "AFc2Lujycfym",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%time\n",
        "# Création d'une boucle pour ne pas relancer le modéle :\n",
        "if not os.path.exists(\"/content/drive/My Drive/Colab Notebooks/Projet_5/w2v_model_train\") :\n",
        "\n",
        "  # Création d'un modéle :\n",
        "  w2v = Word2Vec(min_count=30,\n",
        "                vector_size = 300)\n",
        "\n",
        "  # Nourrir le modéle avec nos phrases :\n",
        "  w2v.build_vocab(corpus, progress_per = 1000)\n",
        "\n",
        "  # Entrainement du modéle :\n",
        "  w2v.train(corpus, total_examples=w2v.corpus_count, epochs=100)\n",
        "\n",
        "  # Sauvegarder le modéle :\n",
        "  w2v.save(\"/content/drive/My Drive/Colab Notebooks/Projet_5/w2v_model_train\")\n",
        "\n",
        "else :\n",
        "  # si le modéle est dans la racine, lance directement le modéle  \n",
        "  w2v = Word2vec.load(\"/content/drive/My Drive/Colab Notebooks/Projet_5/w2v_model_train\")\"\"\""
      ],
      "metadata": {
        "id": "0vH6rbPaNUWI"
      },
      "id": "0vH6rbPaNUWI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# librairie à installer :\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "2_vec_model = Sequential(df_modellisation['corpus_finish'])\n",
        "2_vec_model.add(Embedding(vocab_size, embedding_dim))\n",
        "2_vec_model.add(GlobalAveragePooling1D())\n",
        "2_vec_model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "2_vec_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "2vec_sentences = 2_vec_model.fit(X, y,\n",
        "    batch_size = 256,\n",
        "    epochs=10)\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0oI-UoXqPGgZ"
      },
      "id": "0oI-UoXqPGgZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Les données du cours Openclassrooms m'ont fortement aidé pour créer cette algorithme \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-YT6ztpbm_MD"
      },
      "id": "-YT6ztpbm_MD"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==4.2.0 # -> pour relancer le modéle "
      ],
      "metadata": {
        "id": "7Uyd-9DQ1EIP"
      },
      "id": "7Uyd-9DQ1EIP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gensim.__version__)"
      ],
      "metadata": {
        "id": "O2QZH6CVnYc7"
      },
      "id": "O2QZH6CVnYc7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_size=300\n",
        "w2v_window=5\n",
        "w2v_min_count=25\n",
        "w2v_epochs=100\n",
        "maxlen = 270 # taille des phrases à vérifier pour le max\n",
        "sentences = df_modellisation['corpus_finish'].tolist()\n",
        "sentences = [gensim.utils.simple_preprocess(text) for text in sentences]"
      ],
      "metadata": {
        "id": "uzNLK46CblxZ"
      },
      "id": "uzNLK46CblxZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Création et entraînement du modèle Word2Vec\n",
        "\n",
        "print(\"Build & train Word2Vec model ...\")\n",
        "w2v_model = gensim.models.Word2Vec(min_count=w2v_min_count, window=w2v_window,\n",
        "                                                vector_size=w2v_size,\n",
        "                                                seed=42,\n",
        "                                                workers=1)\n",
        "#                                                workers=multiprocessing.cpu_count())\n",
        "w2v_model.build_vocab(sentences)\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=w2v_epochs)\n",
        "model_vectors = w2v_model.wv\n",
        "w2v_words = model_vectors.index_to_key\n",
        "print(\"Vocabulary size: %i\" % len(w2v_words))\n",
        "print(\"Word2Vec trained\")"
      ],
      "metadata": {
        "id": "9H-4t6oLbl_E"
      },
      "id": "9H-4t6oLbl_E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.save(\"/content/drive/My Drive/Colab Notebooks/Projet_5/word2vec.model\")\n",
        "w2v_model = Word2Vec.load(\"/content/drive/My Drive/Colab Notebooks/Projet_5/word2vec.model\")"
      ],
      "metadata": {
        "id": "lr-jSezW0vmz"
      },
      "id": "lr-jSezW0vmz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Préparation des sentences (tokenization)\n",
        "\n",
        "print(\"Fit Tokenizer ...\")\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "x_sentences = pad_sequences(tokenizer.texts_to_sequences(sentences),\n",
        "                                                     maxlen=maxlen,\n",
        "                                                     padding='post') \n",
        "                                                   \n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "print(\"Number of unique words: %i\" % num_words)"
      ],
      "metadata": {
        "id": "25MM43YmbmLt"
      },
      "id": "25MM43YmbmLt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ffda89",
      "metadata": {
        "id": "33ffda89"
      },
      "outputs": [],
      "source": [
        "# Création de la matrice d'embedding\n",
        "\n",
        "print(\"Create Embedding matrix ...\")\n",
        "w2v_size = 300\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "embedding_matrix = np.zeros((vocab_size, w2v_size))\n",
        "i=0\n",
        "j=0\n",
        "    \n",
        "for word, idx in word_index.items():\n",
        "    i +=1\n",
        "    if word in w2v_words:\n",
        "        j +=1\n",
        "        embedding_vector = model_vectors[word]\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[idx] = model_vectors[word]\n",
        "            \n",
        "word_rate = np.round(j/i,4)\n",
        "print(\"Word embedding rate : \", word_rate)\n",
        "print(\"Embedding matrix: %s\" % str(embedding_matrix.shape))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Création du modèle\n",
        "\n",
        "input=Input(shape=(len(x_sentences),maxlen),dtype='float64')\n",
        "word_input=Input(shape=(maxlen,),dtype='float64')  \n",
        "word_embedding=Embedding(input_dim=vocab_size,\n",
        "                         output_dim=w2v_size,\n",
        "                         weights = [embedding_matrix],\n",
        "                         input_length=maxlen)(word_input)\n",
        "word_vec=GlobalAveragePooling1D()(word_embedding)  \n",
        "embed_model = Model([word_input],word_vec)\n",
        "\n",
        "embed_model.summary()"
      ],
      "metadata": {
        "id": "EVGBgQ950vQs"
      },
      "id": "EVGBgQ950vQs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = x_sentences # a modifier par tfidf et par wordtovec\n",
        "y = Y\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "JCZQrSVrFcYe"
      },
      "id": "JCZQrSVrFcYe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_metrics_word2vec = {}"
      ],
      "metadata": {
        "id": "RlWUYzqvEJBg"
      },
      "id": "RlWUYzqvEJBg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression Logistique :"
      ],
      "metadata": {
        "id": "KUKQNOMxEKTy"
      },
      "id": "KUKQNOMxEKTy"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = regression_log (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_word2vec, \"word2vec_reg_log\")"
      ],
      "metadata": {
        "id": "Ud5JwJHJEH6u"
      },
      "id": "Ud5JwJHJEH6u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest :"
      ],
      "metadata": {
        "id": "nFmdSQSRENrb"
      },
      "id": "nFmdSQSRENrb"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = random_forest (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_word2vec, \"word2vec_random_forest\")"
      ],
      "metadata": {
        "id": "gSg58zOPEH_Q"
      },
      "id": "gSg58zOPEH_Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Classifier :"
      ],
      "metadata": {
        "id": "K0i0_0ubEOnE"
      },
      "id": "K0i0_0ubEOnE"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = decision_tree (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_word2vec, \"word2vec_decision_tree\")"
      ],
      "metadata": {
        "id": "Zdlxwe6qEIEO"
      },
      "id": "Zdlxwe6qEIEO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K.N.N :"
      ],
      "metadata": {
        "id": "cPudT9dvEPs1"
      },
      "id": "cPudT9dvEPs1"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = KNeighbors (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_word2vec, \"word2vec_knn\")"
      ],
      "metadata": {
        "id": "NEmQMAq6EIK8"
      },
      "id": "NEmQMAq6EIK8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Xgboost :"
      ],
      "metadata": {
        "id": "E8HrRZ5gEQfa"
      },
      "id": "E8HrRZ5gEQfa"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = xgboost (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_word2vec, \"word2vec_xgboost\")"
      ],
      "metadata": {
        "id": "sVMOfqkY0vS5"
      },
      "id": "sVMOfqkY0vS5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting :"
      ],
      "metadata": {
        "id": "QMgqCw0JyUFu"
      },
      "id": "QMgqCw0JyUFu"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = gradient_boost (X_train, y_train, X_test)\n",
        "# model_svc = multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_word2vec, \"word2vec_gradient_boost\")"
      ],
      "metadata": {
        "id": "uul_dlILyUN_"
      },
      "id": "uul_dlILyUN_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_word2vec = pd.DataFrame.from_dict(model_metrics_word2vec)\n",
        "# score_bow = score_bow.style.applymap(color_yellow).applymap(make_bold)\n",
        "print(\"-\"*100)\n",
        "print(\"-\"*42 + f\"Via le word2vec :\" + \"-\"*42)\n",
        "print(\"-\"*100)\n",
        "display(score_word2vec)"
      ],
      "metadata": {
        "id": "2cnCwU-GCPmJ"
      },
      "id": "2cnCwU-GCPmJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataframe des scores pour le word2vec :"
      ],
      "metadata": {
        "id": "Y_lrRi2Dxeq8"
      },
      "id": "Y_lrRi2Dxeq8"
    },
    {
      "cell_type": "code",
      "source": [
        "score_word2vec.to_csv(\"/content/drive/My Drive/Colab Notebooks/Projet_5/Resultat_score_word2vec.csv\") # Cela permettra d'éviter d'attendre de relancer le notebook."
      ],
      "metadata": {
        "id": "q0yJ3uRSCcyK"
      },
      "id": "q0yJ3uRSCcyK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "036cff42",
      "metadata": {
        "id": "036cff42"
      },
      "source": [
        "## Algorithme utilisant Bert : "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train test via Bert :"
      ],
      "metadata": {
        "id": "rdZmIT0VuS8y"
      },
      "id": "rdZmIT0VuS8y"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZtaZAOtRlup6"
      },
      "id": "ZtaZAOtRlup6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# source : https://towardsdatascience.com/multi-class-classification-with-transformers-6cf7b59a033a"
      ],
      "metadata": {
        "id": "HxnMEj3pSiwz"
      },
      "id": "HxnMEj3pSiwz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting dimension :\n",
        "seq_len = 270\n",
        "num_samples = len(df_modellisation)\n",
        "\n",
        "# initialize empty zero arrays\n",
        "Xids = np.zeros((num_samples, seq_len))\n",
        "Xmask = np.zeros((num_samples, seq_len))\n",
        "\n",
        "# check shape\n",
        "display(Xids.shape)\n",
        "display(Xmask.shape)\n",
        "# initialize tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "for i, phrase in enumerate(df_modellisation['corpus_finish']):\n",
        "    tokens = tokenizer.encode_plus(phrase, max_length=seq_len, truncation=True,\n",
        "                                   padding='max_length', add_special_tokens=True,\n",
        "                                   return_tensors='tf')\n",
        "    # assign tokenized outputs to respective rows in numpy arrays\n",
        "    Xids[i, :] = tokens['input_ids']\n",
        "    Xmask[i, :] = tokens['attention_mask']"
      ],
      "metadata": {
        "id": "h9Zq-wBXSizB"
      },
      "id": "h9Zq-wBXSizB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#n_tags = len(df_modellisation['tags_preprocessing'])\n",
        "tag_num = df_modellisation['tags_final'].explode().nunique()\n",
        "labels = np.zeros((num_samples, tag_num))\n",
        "tag_to_num = dict(zip(df_modellisation['tags_final'].explode().unique(), range(tag_num)))\n",
        "for index, tag_list in enumerate (df_modellisation['tags_final']):\n",
        "  tag_list = [tag_to_num[tag] for tag in tag_list]\n",
        "  for n_tags in tag_list:\n",
        "    labels[index, n_tags] = 1"
      ],
      "metadata": {
        "id": "LoI5i_4LSjAd"
      },
      "id": "LoI5i_4LSjAd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the dataset object\n",
        "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n",
        "display(dataset.take(1))\n",
        "\n",
        "def map_func(input_ids, masks, labels):\n",
        "    # we convert our three-item tuple into a two-item tuple where the input item is a dictionary\n",
        "    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
        "\n",
        "# then we use the dataset map method to apply this transformation\n",
        "dataset = dataset.map(map_func)"
      ],
      "metadata": {
        "id": "e44o7oapgeiV"
      },
      "id": "e44o7oapgeiV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we will split into batches of 16\n",
        "batch_size = 16\n",
        "\n",
        "# shuffle and batch - dropping any remaining samples that don't cleanly\n",
        "# fit into a batch of 16\n",
        "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
        "display(dataset.take(1))"
      ],
      "metadata": {
        "id": "kJUlEb-0gahS"
      },
      "id": "kJUlEb-0gahS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set split size (33% training data) and calculate training set size\n",
        "split = 0.33\n",
        "size = int((Xids.shape[0]/batch_size)*split)\n",
        "\n",
        "# get training and validation sets\n",
        "train_ds = dataset.take(size)\n",
        "test_ds = dataset.skip(size)\n",
        "\n",
        "del dataset # free memoire"
      ],
      "metadata": {
        "id": "xH5pA5CkZR2n"
      },
      "id": "xH5pA5CkZR2n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TFAutoModel for TensorFlow\n",
        "from transformers import TFAutoModel\n",
        "\n",
        "bert = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "display(bert.summary())"
      ],
      "metadata": {
        "id": "1d4Z6hrjZSSV"
      },
      "id": "1d4Z6hrjZSSV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(270,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(270,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert.bert(input_ids, attention_mask=mask)[1]  # access pooled activations with [1]\n",
        "\n",
        "# convert bert embeddings into 5 output classes\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
        "y = tf.keras.layers.Dense(28, activation='softmax', name='outputs')(x)"
      ],
      "metadata": {
        "id": "l9PYkX8nuz3u"
      },
      "id": "l9PYkX8nuz3u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize model\n",
        "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "# freeze bert layer\n",
        "model.layers[2].trainable = False\n",
        "display(model.summary())"
      ],
      "metadata": {
        "id": "mjRa5Wh0fQsa"
      },
      "id": "mjRa5Wh0fQsa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=1e-5, decay=1e-6)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "# Measure accuracy\n",
        "auc_area = tf.keras.metrics.AUC()\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[auc_area])"
      ],
      "metadata": {
        "id": "Cj2hWR8xeSp4"
      },
      "id": "Cj2hWR8xeSp4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = tf.keras.metrics.Accuracy()\n",
        "Recall = tf.keras.metrics.Recall()\n",
        "auc_area = tf.keras.metrics.AUC()"
      ],
      "metadata": {
        "id": "vN8jPlEdGDIf"
      },
      "id": "vN8jPlEdGDIf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data = test_ds,\n",
        "    epochs = 3,\n",
        "    verbose =2)"
      ],
      "metadata": {
        "id": "hzHs_xhveazt"
      },
      "id": "hzHs_xhveazt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# 5 questions of the test set are evaluated\n",
        "tag_list = df_modellisation['tags_final'].explode().unique()\n",
        "\n",
        "for index in range(0,5):\n",
        "    data = test_ds.take(1)\n",
        "    \n",
        "    # Recovering tags\n",
        "    label_arr = list(data)[0][1][index]\n",
        "    tag_doc = (label_arr.numpy().astype(bool) * tag_list)\n",
        "    tag_doc = tag_doc[tag_doc!='']\n",
        "    \n",
        "    # Recovering doc\n",
        "    doc = tokenizer.decode([n.numpy() for n in list(data)[0][0]['input_ids'][0] if n != 0])\n",
        "    \n",
        "    # Predictiong value\n",
        "    pred_arr = model.predict(data)[0]\n",
        "    pred_tag = tag_list[pred_arr.argmax()]\n",
        "    \n",
        "    \n",
        "    print('-'*50)\n",
        "    print('Tag : ', tag_doc)\n",
        "    print('-'*50)\n",
        "    print('Prediction : ', pred_tag)\n",
        "    print('-'*50)\n",
        "    print(doc)\n",
        "    print('')\n",
        "    print('-'*50)\n",
        "    print('')\n",
        "    print('')"
      ],
      "metadata": {
        "id": "DDfs1odKea7F"
      },
      "id": "DDfs1odKea7F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xDy41bor7rSF"
      },
      "id": "xDy41bor7rSF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e4K3I9KJgjj_"
      },
      "id": "e4K3I9KJgjj_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zjEVjzaPgjo_"
      },
      "id": "zjEVjzaPgjo_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5uYoKXHAgjrQ"
      },
      "id": "5uYoKXHAgjrQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CmlRE0qDgjtg"
      },
      "id": "CmlRE0qDgjtg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396a00a9",
      "metadata": {
        "id": "396a00a9"
      },
      "outputs": [],
      "source": [
        "\"\"\"!pip install transformers\n",
        "os.environ[\"TF_KERAS\"]='1'\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Fonction de préparation des sentences\n",
        "def bert_inp_fct(sentences, bert_tokenizer, max_length) :\n",
        "    input_ids=[]\n",
        "    token_type_ids = []\n",
        "    attention_mask=[]\n",
        "    bert_inp_tot = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        bert_inp = bert_tokenizer.encode_plus(sent,\n",
        "                                              add_special_tokens = True,\n",
        "                                              max_length = max_length,\n",
        "                                              padding='max_length',\n",
        "                                              return_attention_mask = True, \n",
        "                                              return_token_type_ids=True,\n",
        "                                              truncation=True,\n",
        "                                              return_tensors=\"tf\")\n",
        "    \n",
        "        input_ids.append(bert_inp['input_ids'][0])\n",
        "        token_type_ids.append(bert_inp['token_type_ids'][0])\n",
        "        attention_mask.append(bert_inp['attention_mask'][0])\n",
        "        bert_inp_tot.append((bert_inp['input_ids'][0], \n",
        "                             bert_inp['token_type_ids'][0], \n",
        "                             bert_inp['attention_mask'][0]))\n",
        "\n",
        "    input_ids = np.asarray(input_ids)\n",
        "    token_type_ids = np.asarray(token_type_ids)\n",
        "    attention_mask = np.array(attention_mask)\n",
        "    \n",
        "    return input_ids, token_type_ids, attention_mask, bert_inp_tot\n",
        "    \n",
        "\n",
        "# Fonction de création des features\n",
        "def feature_BERT_fct(model, model_type, sentences, max_length, b_size, mode='HF') :\n",
        "    batch_size = b_size\n",
        "    batch_size_pred = b_size\n",
        "    bert_tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
        "    time1 = time.time()\n",
        "\n",
        "    for step in range(len(sentences)//batch_size) :\n",
        "        idx = step*batch_size\n",
        "        input_ids, token_type_ids, attention_mask, bert_inp_tot = bert_inp_fct(sentences[idx:idx+batch_size], \n",
        "                                                                      bert_tokenizer, max_length)\n",
        "        \n",
        "        if mode=='HF' :    # Bert HuggingFace\n",
        "            outputs = model.predict([input_ids, attention_mask, token_type_ids], batch_size=batch_size_pred)\n",
        "            last_hidden_states = outputs.last_hidden_state\n",
        "\n",
        "        if mode=='TFhub' : # Bert Tensorflow Hub\n",
        "            text_preprocessed = {\"input_word_ids\" : input_ids, \n",
        "                                 \"input_mask\" : attention_mask, \n",
        "                                 \"input_type_ids\" : token_type_ids}\n",
        "            outputs = model(text_preprocessed)\n",
        "            last_hidden_states = outputs['sequence_output']\n",
        "             \n",
        "        if step ==0 :\n",
        "            last_hidden_states_tot = last_hidden_states\n",
        "            last_hidden_states_tot_0 = last_hidden_states\n",
        "        else :\n",
        "            last_hidden_states_tot = np.concatenate((last_hidden_states_tot,last_hidden_states))\n",
        "    \n",
        "    features_bert = np.array(last_hidden_states_tot).mean(axis=1)\n",
        "    \n",
        "    time2 = np.round(time.time() - time1,0)\n",
        "    print(\"temps traitement : \", time2)\n",
        "     \n",
        "    return features_bert, last_hidden_states_tot\"\"\""
      ],
      "metadata": {
        "id": "JWvTTK4KZZZW"
      },
      "id": "JWvTTK4KZZZW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"max_length = 270 # taille des phrases à vérifier pour le max\n",
        "batch_size = 5\n",
        "model_type = 'bert-base-uncased'\n",
        "model = TFAutoModel.from_pretrained(model_type)\n",
        "sentences = df_modellisation['corpus_finish'].tolist()\"\"\""
      ],
      "metadata": {
        "id": "_IvJH3w4ZZl6"
      },
      "id": "_IvJH3w4ZZl6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58c91cbb",
      "metadata": {
        "id": "58c91cbb"
      },
      "outputs": [],
      "source": [
        "\"\"\"%%time\n",
        "import time\n",
        "# Création des features\n",
        "\n",
        "features_bert, last_hidden_states_tot = feature_BERT_fct(model, model_type, sentences, \n",
        "                                                         max_length, batch_size, mode='HF')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"features_bert\"\"\""
      ],
      "metadata": {
        "id": "V_7junPuH6TO"
      },
      "id": "V_7junPuH6TO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"X = features_bert\n",
        "y = Y\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\"\"\""
      ],
      "metadata": {
        "id": "OMAbfWU1aiD-"
      },
      "id": "OMAbfWU1aiD-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression Logistique :"
      ],
      "metadata": {
        "id": "05U3I71GuZB0"
      },
      "id": "05U3I71GuZB0"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%time\n",
        "y_pred = regression_log (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics, \"BERT_gradient_boost\")\"\"\""
      ],
      "metadata": {
        "id": "i1Jc6SD6bHOz"
      },
      "id": "i1Jc6SD6bHOz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest :"
      ],
      "metadata": {
        "id": "sJvtMGBrurN2"
      },
      "id": "sJvtMGBrurN2"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%time\n",
        "y_pred = random_forest (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics, \"BERT_gradient_boost\")\"\"\""
      ],
      "metadata": {
        "id": "ct0qjFUcvD_H"
      },
      "id": "ct0qjFUcvD_H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Classifier :"
      ],
      "metadata": {
        "id": "WMXVYhVeuvtX"
      },
      "id": "WMXVYhVeuvtX"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%time\n",
        "y_pred = decision_tree (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics, \"BERT_gradient_boost\")\"\"\""
      ],
      "metadata": {
        "id": "eKLi9P5evzjN"
      },
      "id": "eKLi9P5evzjN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K.N.N :"
      ],
      "metadata": {
        "id": "1kGcV0lluyt3"
      },
      "id": "1kGcV0lluyt3"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%time\n",
        "y_pred = KNeighbors (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics, \"BERT_gradient_boost\")\"\"\""
      ],
      "metadata": {
        "id": "tSpTIkF6v3AH"
      },
      "id": "tSpTIkF6v3AH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Xgboost :"
      ],
      "metadata": {
        "id": "PuKJwEhKu3fR"
      },
      "id": "PuKJwEhKu3fR"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%time\n",
        "y_pred = xgboost (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics, \"BERT_gradient_boost\")\"\"\""
      ],
      "metadata": {
        "id": "uc96UQjQv4fT"
      },
      "id": "uc96UQjQv4fT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting :"
      ],
      "metadata": {
        "id": "cUElArDjzQLs"
      },
      "id": "cUElArDjzQLs"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"%%time\n",
        "y_pred = gradient_boost (X_train, y_train, X_test)\n",
        "# model_svc = multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics, \"BERT_gradient_boost\")\"\"\""
      ],
      "metadata": {
        "id": "EoInpkh6zQTs"
      },
      "id": "EoInpkh6zQTs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithme utilisant USE :"
      ],
      "metadata": {
        "id": "28iT09cYUcwy"
      },
      "id": "28iT09cYUcwy"
    },
    {
      "cell_type": "code",
      "source": [
        "model_metrics_use = {}"
      ],
      "metadata": {
        "id": "Ozy_fVXiJV24"
      },
      "id": "Ozy_fVXiJV24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train test via USE :"
      ],
      "metadata": {
        "id": "LtMMtY5hwXSH"
      },
      "id": "LtMMtY5hwXSH"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "model =  tf_hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "def embed(input):\n",
        "  return model(input)"
      ],
      "metadata": {
        "id": "apXmupIjU2dj"
      },
      "id": "apXmupIjU2dj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = embed(df_modellisation['corpus_finish'].tolist())"
      ],
      "metadata": {
        "id": "2X0RphJSU2v3"
      },
      "id": "2X0RphJSU2v3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = np.array(x1)"
      ],
      "metadata": {
        "id": "nLT9R6K1U2-0"
      },
      "id": "nLT9R6K1U2-0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "795b0b93",
      "metadata": {
        "id": "795b0b93"
      },
      "outputs": [],
      "source": [
        "x1.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = x1 # pour la méthode USE\n",
        "y = Y\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "hJbOOaotWnzZ"
      },
      "id": "hJbOOaotWnzZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression Logistique :"
      ],
      "metadata": {
        "id": "0wKRJKPwwc-3"
      },
      "id": "0wKRJKPwwc-3"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = regression_log (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_use, \"USE_reg_log\")"
      ],
      "metadata": {
        "id": "u8Pd19HAWxB1"
      },
      "id": "u8Pd19HAWxB1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest :"
      ],
      "metadata": {
        "id": "jkC_KlItwgJH"
      },
      "id": "jkC_KlItwgJH"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = random_forest (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_use, \"USE_random_forest\")"
      ],
      "metadata": {
        "id": "YswC7WPiWxYt"
      },
      "id": "YswC7WPiWxYt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Classifier :"
      ],
      "metadata": {
        "id": "yESr5wXQwjEf"
      },
      "id": "yESr5wXQwjEf"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = decision_tree (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_use, \"USE_decision_tree\")"
      ],
      "metadata": {
        "id": "oRFhSxn_wjiw"
      },
      "id": "oRFhSxn_wjiw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K.N.N :"
      ],
      "metadata": {
        "id": "6wfH1bOhwnrz"
      },
      "id": "6wfH1bOhwnrz"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = KNeighbors (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_use, \"USE_knn\")"
      ],
      "metadata": {
        "id": "8kzaWJiYwqhM"
      },
      "id": "8kzaWJiYwqhM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Xgboost :"
      ],
      "metadata": {
        "id": "o0FRYrswwrLg"
      },
      "id": "o0FRYrswwrLg"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = xgboost (X_train, y_train, X_test)\n",
        "# multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_use, \"USE_xgboost\")"
      ],
      "metadata": {
        "id": "onL2L0Oqwqld"
      },
      "id": "onL2L0Oqwqld",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting :"
      ],
      "metadata": {
        "id": "8R0eU7MSzJPz"
      },
      "id": "8R0eU7MSzJPz"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = gradient_boost (X_train, y_train, X_test)\n",
        "# model_svc = multiscore (y_test, y_pred)\n",
        "dico_metric (model_metrics_use, \"USE_gradient_boost\")"
      ],
      "metadata": {
        "id": "K4UwpOwXzJam"
      },
      "id": "K4UwpOwXzJam",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_use = pd.DataFrame.from_dict(model_metrics_use)\n",
        "# score_bow = score_bow.style.applymap(color_yellow).applymap(make_bold)\n",
        "print(\"-\"*100)\n",
        "print(\"-\"*42 + f\"Via le use :\" + \"-\"*42)\n",
        "print(\"-\"*100)\n",
        "display(score_use)"
      ],
      "metadata": {
        "id": "v4TlH95zJiuq"
      },
      "id": "v4TlH95zJiuq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataframe des scores pour le USE :"
      ],
      "metadata": {
        "id": "G7YTbsofxjHQ"
      },
      "id": "G7YTbsofxjHQ"
    },
    {
      "cell_type": "code",
      "source": [
        "score_use.to_csv(\"/content/drive/My Drive/Colab Notebooks/Projet_5/Resultat_score_use.csv\", index=False) # Cela permettra d'éviter d'attendre de relancer le notebook."
      ],
      "metadata": {
        "id": "b28Qz099Jldl"
      },
      "id": "b28Qz099Jldl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "30d53b43",
      "metadata": {
        "id": "30d53b43"
      },
      "source": [
        "## Choix du meilleur algorithme :"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnGVXi6ktYS8"
      },
      "id": "gnGVXi6ktYS8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Styling\n",
        "def color_green(val):\n",
        "    color = 'green' if val > .2 else 'black'\n",
        "    return 'color: {col}'.format(col=color)\n",
        "\n",
        "def make_bold(val):\n",
        "    weight = 700 if val > .2 else 700\n",
        "    return 'font-weight: {weight}'.format(weight=weight)"
      ],
      "metadata": {
        "id": "nugBAL9YvN7A"
      },
      "id": "nugBAL9YvN7A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_metrics = pd.DataFrame.from_dict(model_metrics)\n",
        "score_metrics = score_metrics.style.applymap(color_green).applymap(make_bold)\n",
        "score_metrics"
      ],
      "metadata": {
        "id": "eAEutat8gpNc"
      },
      "id": "eAEutat8gpNc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "834322a5",
      "metadata": {
        "id": "834322a5"
      },
      "outputs": [],
      "source": [
        "# FAIRE UN DICTIONNAIRE POUR LES ALGORITHMES \n",
        "## Algo BOW algo tf-idf Algo USE algo word2vec SONT OKAY\n",
        "### Faire un dictionnaire pour chaque utilisation ou global ?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "384px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}